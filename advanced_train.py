"""
ê³ ê¸‰ ë‹¤ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import argparse
import logging
import sys
from pathlib import Path

from advanced_config import (
    AdvancedTrainingConfig, TrainingStageConfig, 
    DataSplitConfig, EarlyStoppingConfig, MultiStageTrainingConfig
)
from advanced_trainer import AdvancedSignLanguageTrainer

def setup_logging(log_level: str = "INFO"):
    """ë¡œê¹… ì„¤ì • - í›ˆë ¨ ì§„í–‰ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•´ INFO ë ˆë²¨ ìœ ì§€"""
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('advanced_training.log', encoding='utf-8')
        ]
    )

def create_custom_config(args) -> AdvancedTrainingConfig:
    """ì»¤ìŠ¤í…€ ì„¤ì • ìƒì„±"""
    config = AdvancedTrainingConfig()
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    if args.seed:
        config.random_seed.seed = args.seed
    
    if args.experiment_name:
        config.experiment_name = args.experiment_name
        
    if args.data_dir:
        config.pose_data_dir = args.data_dir
        
    if args.annotation_path:
        config.annotation_path = args.annotation_path
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device:
        config.device = args.device
    
    # ë©€í‹° GPU ì„¤ì •
    if args.multi_gpu:
        config.multi_gpu = args.multi_gpu
        
    if hasattr(args, 'data_parallel') and args.data_parallel is not None:
        config.use_data_parallel = args.data_parallel
    
    # ë°ì´í„° ë¶„í•  ë¹„ìœ¨ ì„¤ì •
    if args.train_ratio:
        config.data_split.train_ratio = args.train_ratio
        config.data_split.val_ratio = (1.0 - args.train_ratio) * 0.75
        config.data_split.test_ratio = (1.0 - args.train_ratio) * 0.25
    
    # ì–¼ë¦¬ìŠ¤íƒ‘ ì„¤ì •
    if args.patience:
        config.early_stopping.patience = args.patience
    
    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ
    if args.quick_test:
        # ë‹¨ê³„ ìˆ˜ ì¤„ì´ê¸°
        config.multi_stage.stages = config.multi_stage.stages[:2]
        for stage in config.multi_stage.stages:
            stage.num_epochs = min(3, stage.num_epochs)
            stage.batch_size = min(16, stage.batch_size)
        config.early_stopping.patience = 3
        config.experiment_name = "quick_test"
    
    # ì»¤ìŠ¤í…€ ë‹¨ê³„ ì„¤ì •
    if args.stages_config:
        config = create_stages_from_config(config, args.stages_config)
    
    return config

def create_stages_from_config(config: AdvancedTrainingConfig, stages_config: str) -> AdvancedTrainingConfig:
    """ì„¤ì • íŒŒì¼ì—ì„œ ë‹¨ê³„ êµ¬ì„± ë¡œë“œ"""
    if stages_config == "conservative":
        # ë³´ìˆ˜ì ì¸ í•™ìŠµ (ì‘ì€ í•™ìŠµë¥ , ê¸´ í•™ìŠµ)
        config.multi_stage.stages = [
            TrainingStageConfig(
                name="conservative_baseline",
                description="ë³´ìˆ˜ì  ê¸°ë³¸ í•™ìŠµ",
                num_epochs=50,
                batch_size=32,
                learning_rate=5e-5,
                enable_augmentation=False
            ),
            TrainingStageConfig(
                name="conservative_augmentation",
                description="ë³´ìˆ˜ì  ì¦ê°• í•™ìŠµ",
                num_epochs=40,
                batch_size=24,
                learning_rate=2e-5,
                enable_augmentation=True,
                augmentation_strength=0.7
            )
        ]
    elif stages_config == "aggressive":
        # ê³µê²©ì ì¸ í•™ìŠµ (í° í•™ìŠµë¥ , ê°•í•œ ì¦ê°•)
        config.multi_stage.stages = [
            TrainingStageConfig(
                name="aggressive_baseline",
                description="ê³µê²©ì  ê¸°ë³¸ í•™ìŠµ",
                num_epochs=20,
                batch_size=48,
                learning_rate=2e-4,
                enable_augmentation=False
            ),
            TrainingStageConfig(
                name="aggressive_augmentation",
                description="ê³µê²©ì  ì¦ê°• í•™ìŠµ",
                num_epochs=25,
                batch_size=32,
                learning_rate=1e-4,
                enable_augmentation=True,
                augmentation_strength=1.3
            ),
            TrainingStageConfig(
                name="aggressive_regularization",
                description="ê°•í•œ ì •ê·œí™”",
                num_epochs=15,
                batch_size=24,
                learning_rate=5e-5,
                enable_augmentation=True,
                dropout_rate=0.3,
                label_smoothing=0.15
            )
        ]
    elif stages_config == "minimal":
        # ìµœì†Œí•œì˜ ë‹¨ê³„ (ë¹ ë¥¸ ì‹¤í—˜ìš©)
        config.multi_stage.stages = [
            TrainingStageConfig(
                name="minimal_training",
                description="ìµœì†Œí•œì˜ í•™ìŠµ",
                num_epochs=15,
                batch_size=32,
                learning_rate=1e-4,
                enable_augmentation=True,
                augmentation_strength=0.8
            )
        ]
    
    return config

def main():
    parser = argparse.ArgumentParser(description="ê³ ê¸‰ ë‹¤ë‹¨ê³„ ìˆ˜í™” ì¸ì‹ ëª¨ë¸ í•™ìŠµ")
    
    # ê¸°ë³¸ ì„¤ì •
    parser.add_argument("--seed", type=int, default=42, help="ëœë¤ ì‹œë“œ")
    parser.add_argument("--device", choices=["auto", "cuda", "xpu", "cpu"], 
                       default="auto", help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤")
    parser.add_argument("--multi-gpu", action="store_true",
                       help="ë©€í‹° GPU ì‚¬ìš© (CUDAë§Œ ì§€ì›)")
    parser.add_argument("--no-data-parallel", action="store_false", dest="data_parallel",
                       help="DataParallel ì‚¬ìš© ì•ˆí•¨ (ë©€í‹° GPU ì‹œ)")
    parser.add_argument("--experiment-name", type=str, 
                       default="multi_stage_training", help="ì‹¤í—˜ ì´ë¦„")
    
    # ë°ì´í„° ì„¤ì •
    parser.add_argument("--data-dir", type=str, default="./data", 
                       help="í¬ì¦ˆ ë°ì´í„° ë””ë ‰í† ë¦¬")
    parser.add_argument("--annotation-path", type=str, 
                       default="./data/sign_language_dataset_only_sen_lzf.h5",
                       help="ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--train-ratio", type=float, default=0.8,
                       help="í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨")
    
    # í•™ìŠµ ì„¤ì •
    parser.add_argument("--patience", type=int, default=15,
                       help="ì–¼ë¦¬ìŠ¤íƒ‘ patience")
    parser.add_argument("--stages-config", 
                       choices=["default", "conservative", "aggressive", "minimal"],
                       default="default", help="í•™ìŠµ ë‹¨ê³„ êµ¬ì„±")
    
    # ì‹¤í–‰ ì˜µì…˜
    parser.add_argument("--quick-test", action="store_true",
                       help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì‘ì€ ì—í¬í¬ ìˆ˜)")
    parser.add_argument("--log-level", choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                       default="INFO", help="ë¡œê·¸ ë ˆë²¨")
    parser.add_argument("--resume", type=str, help="ì¬ê°œí•  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    # ë¡œê¹… ì„¤ì •
    setup_logging(args.log_level)
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸš€ ê³ ê¸‰ ë‹¤ë‹¨ê³„ ìˆ˜í™” ì¸ì‹ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    logger.info("="*80)
    
    try:
        # ì„¤ì • ìƒì„±
        config = create_custom_config(args)
        
        logger.info(f"âš™ï¸ ì‹¤í—˜ ì„¤ì •:")
        logger.info(f"  ì‹¤í—˜ëª…: {config.experiment_name}")
        logger.info(f"  ëœë¤ ì‹œë“œ: {config.random_seed.seed}")
        logger.info(f"  ë””ë°”ì´ìŠ¤: {config.device}")
        logger.info(f"  ë°ì´í„° ë¶„í• : í›ˆë ¨ {config.data_split.train_ratio:.1%}, "
                   f"ê²€ì¦ {config.data_split.val_ratio:.1%}, í…ŒìŠ¤íŠ¸ {config.data_split.test_ratio:.1%}")
        logger.info(f"  í•™ìŠµ ë‹¨ê³„ ìˆ˜: {len(config.multi_stage.stages)}")
        logger.info(f"  ì–¼ë¦¬ìŠ¤íƒ‘ patience: {config.early_stopping.patience}")
        
        # ë‹¨ê³„ë³„ ì„¤ì • ì¶œë ¥
        logger.info(f"\nğŸ“‹ í•™ìŠµ ë‹¨ê³„ ê³„íš:")
        for i, stage in enumerate(config.multi_stage.stages):
            logger.info(f"  Stage {i+1}: {stage.name}")
            logger.info(f"    - ì„¤ëª…: {stage.description}")
            logger.info(f"    - ì—í¬í¬: {stage.num_epochs}, ë°°ì¹˜: {stage.batch_size}")
            logger.info(f"    - í•™ìŠµë¥ : {stage.learning_rate}, ë“œë¡­ì•„ì›ƒ: {stage.dropout_rate}")
            logger.info(f"    - ì¦ê°•: {'âœ…' if stage.enable_augmentation else 'âŒ'}")
        
        # íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í•™ìŠµ ì‹¤í–‰
        trainer = AdvancedSignLanguageTrainer(config)
        results = trainer.train_multi_stage()
        
        logger.info("\nğŸ‰ ëª¨ë“  í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info(f"ì‹¤í—˜ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {config.checkpoint_dir}")
        
        # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
        if 'final_performance' in results:
            final_perf = results['final_performance']
            logger.info(f"\nğŸ† ìµœì¢… ì„±ëŠ¥:")
            logger.info(f"  í…ŒìŠ¤íŠ¸ ì •í™•ë„: {final_perf['test_accuracy']:.3f}")
            logger.info(f"  í…ŒìŠ¤íŠ¸ ì†ì‹¤: {final_perf['test_loss']:.4f}")
        
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ì‚¬ìš©ìì— ì˜í•´ í•™ìŠµì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()