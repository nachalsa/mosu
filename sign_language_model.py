#!/usr/bin/env python3
"""
ì‹¤ì‹œê°„ ìˆ˜í™” ì¸ì‹ ëª¨ë¸ - Sequence-to-Sequence Transformer
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from typing import Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class PositionalEncoding(nn.Module):
    """ìœ„ì¹˜ ì¸ì½”ë”©"""
    
    def __init__(self, d_model: int, max_len: int = 1000, dropout: float = 0.1):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class SpatialEncoder(nn.Module):
    """ê³µê°„ íŠ¹ì§• ì¶”ì¶œê¸° (133ê°œ í‚¤í¬ì¸íŠ¸ â†’ ì„ë² ë”© ì°¨ì›)"""
    
    def __init__(self, input_dim: int = 133 * 3, embed_dim: int = 256, dropout: float = 0.1):
        super().__init__()
        self.input_dim = input_dim
        self.embed_dim = embed_dim
        
        # ê³µê°„ íŠ¹ì§• ì••ì¶•
        self.spatial_layers = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, embed_dim),
            nn.LayerNorm(embed_dim),
            nn.Dropout(dropout)
        )
        
        # í‚¤í¬ì¸íŠ¸ ì¤‘ìš”ë„ ì–´í…ì…˜ (ì„ íƒì )
        self.attention = nn.MultiheadAttention(embed_dim=3, num_heads=1, batch_first=True)
        self.use_attention = False  # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í›„ ê²°ì •
        
    def forward(self, x):
        # x: [batch, seq_len, 133, 3]
        batch_size, seq_len, n_keypoints, coords = x.shape
        
        if self.use_attention:
            # í‚¤í¬ì¸íŠ¸ ì–´í…ì…˜ ì ìš© (ì‹¤í—˜ì )
            x_reshaped = x.view(batch_size * seq_len, n_keypoints, coords)
            attn_out, _ = self.attention(x_reshaped, x_reshaped, x_reshaped)
            x = attn_out.view(batch_size, seq_len, n_keypoints, coords)
        
        # ê³µê°„ ì°¨ì› í‰íƒ„í™” ë° ì„ë² ë”©
        x = x.view(batch_size, seq_len, -1)  # [batch, seq_len, 133*3]
        x = self.spatial_layers(x)  # [batch, seq_len, embed_dim]
        
        return x

class SequenceToSequenceSignModel(nn.Module):
    """Sequence-to-Sequence ìˆ˜í™” ì¸ì‹ ëª¨ë¸"""
    
    def __init__(self,
                 vocab_size: int,
                 embed_dim: int = 256,
                 num_encoder_layers: int = 6,
                 num_decoder_layers: int = 4,
                 num_heads: int = 8,
                 dim_feedforward: int = 1024,
                 dropout: float = 0.1,
                 max_seq_len: int = 500):
        super().__init__()
        
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim
        self.max_seq_len = max_seq_len
        
        # 1. ê³µê°„ ì¸ì½”ë” (133ê°œ í‚¤í¬ì¸íŠ¸ â†’ ì„ë² ë”©)
        self.spatial_encoder = SpatialEncoder(
            input_dim=133 * 3,
            embed_dim=embed_dim,
            dropout=dropout
        )
        
        # 2. ìœ„ì¹˜ ì¸ì½”ë”©
        self.pos_encoding = PositionalEncoding(embed_dim, max_seq_len, dropout)
        
        # 3. Transformer Encoder (ì‹œê°„ ëª¨ë¸ë§)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim,
            nhead=num_heads,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            activation='gelu',
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(
            encoder_layer, 
            num_layers=num_encoder_layers
        )
        
        # 4. Vocabulary ì„ë² ë”© (ë””ì½”ë” ì…ë ¥ìš©)
        self.vocab_embedding = nn.Embedding(vocab_size, embed_dim)
        self.vocab_pos_encoding = PositionalEncoding(embed_dim, max_seq_len, dropout)
        
        # 5. Transformer Decoder (ì‹œí€€ìŠ¤ ìƒì„±)
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=embed_dim,
            nhead=num_heads,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            activation='gelu',
            batch_first=True
        )
        self.transformer_decoder = nn.TransformerDecoder(
            decoder_layer,
            num_layers=num_decoder_layers
        )
        
        # 6. ì¶œë ¥ í—¤ë“œë“¤
        self.word_classifier = nn.Linear(embed_dim, vocab_size)
        self.boundary_detector = nn.Linear(embed_dim, 3)  # START/CONTINUE/END
        self.confidence_head = nn.Linear(embed_dim, 1)
        
        # 7. ì†ì‹¤ í•¨ìˆ˜ ê°€ì¤‘ì¹˜
        self.register_buffer('word_loss_weight', torch.tensor(1.0))
        self.register_buffer('boundary_loss_weight', torch.tensor(0.5))
        self.register_buffer('confidence_loss_weight', torch.tensor(0.3))
        
        self._init_weights()
    
    def _init_weights(self):
        """ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                torch.nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    torch.nn.init.zeros_(module.bias)
            elif isinstance(module, nn.Embedding):
                torch.nn.init.normal_(module.weight, 0, 0.1)
    
    def create_padding_mask(self, lengths, max_len):
        """íŒ¨ë”© ë§ˆìŠ¤í¬ ìƒì„±"""
        batch_size = len(lengths)
        mask = torch.arange(max_len).expand(batch_size, max_len).to(lengths.device)
        mask = mask >= lengths.unsqueeze(1)
        return mask
    
    def create_causal_mask(self, seq_len):
        """ì¸ê³¼ì  ë§ˆìŠ¤í¬ ìƒì„± (ë””ì½”ë”ìš©)"""
        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()
        return mask
    
    def forward(self, pose_features, vocab_ids=None, frame_masks=None, vocab_masks=None):
        """
        Args:
            pose_features: [batch, seq_len, 133, 3]
            vocab_ids: [batch, vocab_len] (í›ˆë ¨ ì‹œì—ë§Œ)
            frame_masks: [batch, seq_len]
            vocab_masks: [batch, vocab_len]
        """
        batch_size, seq_len = pose_features.shape[:2]
        
        # 1. ê³µê°„ íŠ¹ì§• ì¶”ì¶œ
        encoder_input = self.spatial_encoder(pose_features)  # [batch, seq_len, embed_dim]
        
        # 2. ìœ„ì¹˜ ì¸ì½”ë”© ì¶”ê°€
        encoder_input = encoder_input.transpose(0, 1)  # [seq_len, batch, embed_dim]
        encoder_input = self.pos_encoding(encoder_input)
        encoder_input = encoder_input.transpose(0, 1)  # [batch, seq_len, embed_dim]
        
        # 3. Encoder ë§ˆìŠ¤í¬ ìƒì„±
        if frame_masks is not None:
            encoder_key_padding_mask = ~frame_masks  # True = íŒ¨ë”©
        else:
            encoder_key_padding_mask = None
        
        # 4. Transformer Encoder
        encoder_output = self.transformer_encoder(
            encoder_input, 
            src_key_padding_mask=encoder_key_padding_mask
        )
        
        # 5. í›ˆë ¨ ëª¨ë“œ vs ì¶”ë¡  ëª¨ë“œ
        if self.training and vocab_ids is not None:
            # í›ˆë ¨ ëª¨ë“œ: Teacher Forcing
            return self._forward_training(encoder_output, vocab_ids, vocab_masks)
        else:
            # ì¶”ë¡  ëª¨ë“œ: í”„ë ˆì„ë³„ ë¶„ë¥˜
            return self._forward_inference(encoder_output)
    
    def _forward_training(self, encoder_output, vocab_ids, vocab_masks):
        """í›ˆë ¨ ëª¨ë“œ í¬ì›Œë“œ (Teacher Forcing)"""
        batch_size, vocab_len = vocab_ids.shape
        
        # Decoder ì…ë ¥ ì¤€ë¹„ (ì‹œì‘ í† í° ì¶”ê°€)
        decoder_input_ids = torch.cat([
            torch.zeros(batch_size, 1, dtype=torch.long, device=vocab_ids.device),
            vocab_ids[:, :-1]
        ], dim=1)
        
        # Vocabulary ì„ë² ë”©
        decoder_input = self.vocab_embedding(decoder_input_ids)  # [batch, vocab_len, embed_dim]
        
        # ìœ„ì¹˜ ì¸ì½”ë”© ì¶”ê°€
        decoder_input = decoder_input.transpose(0, 1)
        decoder_input = self.vocab_pos_encoding(decoder_input)
        decoder_input = decoder_input.transpose(0, 1)
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        tgt_mask = self.create_causal_mask(vocab_len).to(vocab_ids.device)
        tgt_key_padding_mask = ~vocab_masks if vocab_masks is not None else None
        
        # Transformer Decoder
        decoder_output = self.transformer_decoder(
            decoder_input,
            encoder_output,
            tgt_mask=tgt_mask,
            tgt_key_padding_mask=tgt_key_padding_mask
        )
        
        # ì¶œë ¥ í—¤ë“œë“¤
        word_logits = self.word_classifier(decoder_output)
        boundary_logits = self.boundary_detector(decoder_output)  
        confidence_scores = self.confidence_head(decoder_output).squeeze(-1)
        
        return {
            'word_logits': word_logits,  # [batch, vocab_len, vocab_size]
            'boundary_logits': boundary_logits,  # [batch, vocab_len, 3]
            'confidence_scores': confidence_scores  # [batch, vocab_len]
        }
    
    def _forward_inference(self, encoder_output):
        """ì¶”ë¡  ëª¨ë“œ í¬ì›Œë“œ (í”„ë ˆì„ë³„ ë¶„ë¥˜)"""
        batch_size, seq_len, embed_dim = encoder_output.shape
        
        # ê° í”„ë ˆì„ì— ëŒ€í•´ ì§ì ‘ ë¶„ë¥˜
        word_logits = self.word_classifier(encoder_output)  # [batch, seq_len, vocab_size]
        boundary_logits = self.boundary_detector(encoder_output)  # [batch, seq_len, 3]
        confidence_scores = self.confidence_head(encoder_output).squeeze(-1)  # [batch, seq_len]
        
        return {
            'word_logits': word_logits,
            'boundary_logits': boundary_logits,
            'confidence_scores': confidence_scores
        }
    
    def compute_loss(self, outputs, targets, vocab_masks=None):
        """ì†ì‹¤ í•¨ìˆ˜ ê³„ì‚°"""
        word_logits = outputs['word_logits']
        boundary_logits = outputs['boundary_logits']
        confidence_scores = outputs['confidence_scores']
        
        vocab_ids = targets['vocab_ids']
        boundary_labels = targets.get('boundary_labels', None)
        confidence_targets = targets.get('confidence_targets', None)
        
        losses = {}
        
        # 1. ë‹¨ì–´ ë¶„ë¥˜ ì†ì‹¤
        word_loss = F.cross_entropy(
            word_logits.view(-1, self.vocab_size),
            vocab_ids.view(-1),
            ignore_index=0  # íŒ¨ë”© ë¬´ì‹œ
        )
        losses['word_loss'] = word_loss
        
        # 2. ê²½ê³„ íƒì§€ ì†ì‹¤ (ìˆëŠ” ê²½ìš°)
        if boundary_labels is not None:
            boundary_loss = F.cross_entropy(
                boundary_logits.view(-1, 3),
                boundary_labels.view(-1),
                ignore_index=-1  # ë¬´ì‹œí•  ë¼ë²¨
            )
            losses['boundary_loss'] = boundary_loss
        else:
            losses['boundary_loss'] = torch.tensor(0.0, device=word_loss.device)
        
        # 3. ì‹ ë¢°ë„ ì†ì‹¤ (ìˆëŠ” ê²½ìš°)
        if confidence_targets is not None:
            confidence_loss = F.mse_loss(
                confidence_scores.view(-1),
                confidence_targets.view(-1)
            )
            losses['confidence_loss'] = confidence_loss
        else:
            losses['confidence_loss'] = torch.tensor(0.0, device=word_loss.device)
        
        # 4. ì´ ì†ì‹¤
        total_loss = (self.word_loss_weight * losses['word_loss'] +
                     self.boundary_loss_weight * losses['boundary_loss'] +
                     self.confidence_loss_weight * losses['confidence_loss'])
        
        losses['total_loss'] = total_loss
        
        return losses

class RealtimeDecoder:
    """ì‹¤ì‹œê°„ ë””ì½”ë”© í´ë˜ìŠ¤"""
    
    def __init__(self, 
                 vocab_size: int,
                 confidence_threshold: float = 0.7,
                 boundary_threshold: float = 0.8):
        self.vocab_size = vocab_size
        self.confidence_threshold = confidence_threshold
        self.boundary_threshold = boundary_threshold
        
        self.state = "WAITING"  # WAITING/IN_WORD/COOLDOWN
        self.current_word_buffer = []
        self.confidence_buffer = []
        self.cooldown_frames = 0
        self.cooldown_duration = 10  # 10í”„ë ˆì„ ëŒ€ê¸°
    
    def process_frame_output(self, word_logits, boundary_logits, confidence):
        """í”„ë ˆì„ë³„ ì¶œë ¥ ì²˜ë¦¬"""
        # ê²½ê³„ ì˜ˆì¸¡
        boundary_probs = F.softmax(boundary_logits, dim=-1)
        boundary_pred = torch.argmax(boundary_probs)
        boundary_conf = torch.max(boundary_probs)
        
        # ë‹¨ì–´ ì˜ˆì¸¡
        word_probs = F.softmax(word_logits, dim=-1)
        word_pred = torch.argmax(word_probs)
        word_conf = torch.max(word_probs)
        
        # ìƒíƒœ ë¨¸ì‹ 
        if self.state == "WAITING":
            if (boundary_pred == 0 and  # START
                boundary_conf > self.boundary_threshold):
                self.state = "IN_WORD"
                self.current_word_buffer = [word_logits]
                self.confidence_buffer = [confidence]
                
        elif self.state == "IN_WORD":
            self.current_word_buffer.append(word_logits)
            self.confidence_buffer.append(confidence)
            
            if (boundary_pred == 2 and  # END
                boundary_conf > self.boundary_threshold and
                len(self.current_word_buffer) > 3):  # ìµœì†Œ ê¸¸ì´
                predicted_word = self.emit_word()
                self.state = "COOLDOWN"
                self.cooldown_frames = self.cooldown_duration
                return predicted_word
                
        elif self.state == "COOLDOWN":
            self.cooldown_frames -= 1
            if self.cooldown_frames <= 0:
                self.state = "WAITING"
        
        return None
    
    def emit_word(self):
        """ë‹¨ì–´ ë°©ì¶œ"""
        if not self.current_word_buffer:
            return None
        
        # ë²„í¼ ë‚´ ì˜ˆì¸¡ë“¤ì˜ ì•™ìƒë¸”
        avg_logits = torch.stack(self.current_word_buffer).mean(dim=0)
        predicted_word = torch.argmax(avg_logits)
        
        # í‰ê·  ì‹ ë¢°ë„
        avg_confidence = torch.stack(self.confidence_buffer).mean()
        
        self.reset_state()
        
        if avg_confidence > self.confidence_threshold:
            return predicted_word.item()
        else:
            return None
    
    def reset_state(self):
        """ìƒíƒœ ì´ˆê¸°í™”"""
        self.current_word_buffer = []
        self.confidence_buffer = []

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ¤– ìˆ˜í™” ì¸ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # ëª¨ë¸ ìƒì„±
    vocab_size = 442  # ì‹¤ì œ vocab í¬ê¸°ì— ë§ì¶° ì¡°ì •
    model = SequenceToSequenceSignModel(
        vocab_size=vocab_size,
        embed_dim=256,
        num_encoder_layers=4,
        num_decoder_layers=3,
        num_heads=8
    )
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„±
    batch_size, seq_len, vocab_len = 2, 100, 5
    pose_features = torch.randn(batch_size, seq_len, 133, 3)
    vocab_ids = torch.randint(1, vocab_size, (batch_size, vocab_len))
    frame_masks = torch.ones(batch_size, seq_len, dtype=torch.bool)
    vocab_masks = torch.ones(batch_size, vocab_len, dtype=torch.bool)
    
    print(f"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ:")
    print(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   - í›ˆë ¨ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # í›ˆë ¨ ëª¨ë“œ í…ŒìŠ¤íŠ¸
    model.train()
    outputs = model(pose_features, vocab_ids, frame_masks, vocab_masks)
    print(f"\nğŸ‹ï¸ í›ˆë ¨ ëª¨ë“œ ì¶œë ¥:")
    print(f"   - Word logits: {outputs['word_logits'].shape}")
    print(f"   - Boundary logits: {outputs['boundary_logits'].shape}")
    print(f"   - Confidence scores: {outputs['confidence_scores'].shape}")
    
    # ì¶”ë¡  ëª¨ë“œ í…ŒìŠ¤íŠ¸
    model.eval()
    with torch.no_grad():
        outputs = model(pose_features, frame_masks=frame_masks)
    print(f"\nğŸ” ì¶”ë¡  ëª¨ë“œ ì¶œë ¥:")
    print(f"   - Word logits: {outputs['word_logits'].shape}")
    print(f"   - Boundary logits: {outputs['boundary_logits'].shape}")
    print(f"   - Confidence scores: {outputs['confidence_scores'].shape}")
    
    # ì‹¤ì‹œê°„ ë””ì½”ë” í…ŒìŠ¤íŠ¸
    decoder = RealtimeDecoder(vocab_size)
    print(f"\nâš¡ ì‹¤ì‹œê°„ ë””ì½”ë” í…ŒìŠ¤íŠ¸:")
    for i in range(20):
        word_logits = outputs['word_logits'][0, i]
        boundary_logits = outputs['boundary_logits'][0, i]
        confidence = outputs['confidence_scores'][0, i]
        
        result = decoder.process_frame_output(word_logits, boundary_logits, confidence)
        if result is not None:
            print(f"   í”„ë ˆì„ {i}: ë‹¨ì–´ {result} ê²€ì¶œ!")
    
    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
