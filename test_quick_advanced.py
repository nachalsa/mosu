#!/usr/bin/env python3
"""
ë¹ ë¥¸ ë‹¤ë‹¨ê³„ í•™ìŠµ í…ŒìŠ¤íŠ¸ (ê° ìŠ¤í…Œì´ì§€ 1 ì—í¬í¬)
"""

import logging
from advanced_config import MultiStageTrainingConfig, TrainingStageConfig
from simple_advanced_trainer import SimpleAdvancedTrainer
from unified_pose_dataloader import UnifiedSignLanguageDataset, create_dataloader
from sign_language_model import SequenceToSequenceSignModel
from advanced_data_utils import create_dataloaders
import torch

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(name)s:%(message)s'
)
logger = logging.getLogger(__name__)

def main():
    """ë¹ ë¥¸ ë‹¤ë‹¨ê³„ í•™ìŠµ í…ŒìŠ¤íŠ¸"""
    
    logger.info("ğŸš€ ë¹ ë¥¸ ë‹¤ë‹¨ê³„ í•™ìŠµ í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    
    # ì„¤ì •
    config = MultiStageTrainingConfig()
    config.seed.fix_all_seeds()
    
    # ë§¤ìš° ì§§ì€ ìŠ¤í…Œì´ì§€ë“¤ë¡œ ì¬ì •ì˜ (ê° 1 ì—í¬í¬)
    config.stages = [
        TrainingStageConfig(
            name="baseline",
            description="ê¸°ë³¸ í•™ìŠµ (1 ì—í¬í¬)",
            epochs=1,
            batch_size=16,  # ë°°ì¹˜ í¬ê¸° ì¦ê°€ë¡œ ì†ë„ í–¥ìƒ
            learning_rate=1e-4,
            dropout=0.1,
            enable_augmentation=False
        ),
        TrainingStageConfig(
            name="augmentation",
            description="ë°ì´í„° ì¦ê°• (1 ì—í¬í¬)",
            epochs=1,
            batch_size=16,
            learning_rate=5e-5,
            dropout=0.15,
            enable_augmentation=True,
            augmentation_strength=0.3
        )
    ]
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ğŸ’» {device.type.upper()} ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
    
    # ê¸°ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ
    logger.info("ğŸ“Š ê¸°ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    base_dataset = UnifiedSignLanguageDataset(
        annotation_file='./data/sign_language_dataset_only_sen_lzf.h5',
        pose_dir='./data',
        enable_augmentation=False
    )
    logger.info(f"âœ… ê¸°ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(base_dataset)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    
    # ë°ì´í„° ë¶„í•  ë° ë¡œë” ìƒì„±
    logger.info("ğŸ“Š ë°ì´í„° ë¶„í•  ë° ë¡œë” ìƒì„± ì¤‘...")
    dataloaders = create_dataloaders(
        base_dataset,
        train_ratio=0.8,
        val_ratio=0.15,
        test_ratio=0.05,
        batch_size=16,
        num_workers=2
    )
    logger.info(f"âœ… ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ")
    
    # ëª¨ë¸ ìƒì„±
    vocab_size = len(base_dataset.words)
    model = SequenceToSequenceSignModel(
        vocab_size=vocab_size,
        input_dim=133 * 3,  # MediaPipe keypoints
        hidden_dim=512,
        num_layers=4
    )
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.info(f"ğŸ“Š ëª¨ë¸ ìƒì„±: {total_params:,} íŒŒë¼ë¯¸í„°")
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = SimpleAdvancedTrainer(
        config=config,
        device=device
    )
    
    # ë‹¤ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰
    logger.info("=" * 60)
    logger.info("ğŸš€ ë¹ ë¥¸ ë‹¤ë‹¨ê³„ í•™ìŠµ ì‹œì‘ (2ë‹¨ê³„, ê° 1ì—í¬í¬)")
    logger.info("=" * 60)
    
    try:
        best_model = trainer.train_multi_stage(model, dataloaders)
        logger.info("âœ… ë‹¤ë‹¨ê³„ í•™ìŠµ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì¢… ëª¨ë¸ íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in best_model.parameters()):,}")
        
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
