# ğŸ¤Ÿ ìˆ˜í™” ì¸ì‹ ì‹œìŠ¤í…œ ì™„ì „ ê°€ì´ë“œ

## ğŸ“Š ì‹œìŠ¤í…œ í˜„í™© (2025-08-10 ê¸°ì¤€)

### ë°ì´í„° í†µê³„
- **ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸**: 101,885ê°œ
- **ìœ íš¨ ì„¸ê·¸ë¨¼íŠ¸**: 74,346ê°œ (ì •ë©´ ì´¬ì˜ + í¬ì¦ˆ ë°ì´í„° ì¡´ì¬)
- **ì–´íœ˜ í¬ê¸°**: 442ê°œ í•œêµ­ì–´ ìˆ˜í™” ë‹¨ì–´
- **í‰ê·  ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´**: 23.7 í”„ë ˆì„
- **í‚¤í¬ì¸íŠ¸**: RTMW ê¸°ë°˜ 133ê°œ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸
- **ë°ì´í„° ì¦ê°•**: âœ… 4ê°€ì§€ ì¦ê°• ê¸°ë²• ì§€ì›

## ğŸ§  ëª¨ë¸ ì•„í‚¤í…ì²˜: Sequence-to-Sequence Transformer

### ì „ì²´ êµ¬ì¡° ê°œìš”
```
ì…ë ¥ ë¹„ë””ì˜¤ â†’ RTMW â†’ 133ê°œ í‚¤í¬ì¸íŠ¸ â†’ ì •ê·œí™” â†’ 
Spatial Encoder â†’ Positional Encoding â†’ Transformer Encoder â†’ 
[í›ˆë ¨ì‹œ: Decoder] | [ì¶”ë¡ ì‹œ: ì§ì ‘ë¶„ë¥˜] â†’ Word/Boundary/Confidence ì¶œë ¥
```

### 1ï¸âƒ£ **ì…ë ¥ ë°ì´í„° ì²˜ë¦¬**

**í‚¤í¬ì¸íŠ¸ êµ¬ì„±**:
- **ì–¼êµ´**: 468ê°œ ëœë“œë§ˆí¬ì—ì„œ í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ
- **í¬ì¦ˆ**: 33ê°œ ëª¸ì²´ í‚¤í¬ì¸íŠ¸ 
- **ì†**: ì¢Œ/ìš°ì† ê° 21ê°œì”© (ì´ 42ê°œ)
- **ì´í•©**: 133ê°œ í‚¤í¬ì¸íŠ¸ Ã— (x, y, confidence) = 399ì°¨ì›

**ì •ê·œí™” ê³¼ì •**:
```python
# ì›ë³¸ ì¢Œí‘œ â†’ 0~1 ì •ê·œí™”
x_normalized = (x - x_min) / (x_max - x_min) * 0.8 + 0.1  # 0.1~0.9 ë²”ìœ„
y_normalized = (y - y_min) / (y_max - y_min) * 0.8 + 0.1
confidence_normalized = confidence / 10.0  # 0~1 ë²”ìœ„
```

### 2ï¸âƒ£ **ê³µê°„ ì¸ì½”ë” (SpatialEncoder)**

**êµ¬ì¡°**:
```python
class SpatialEncoder(nn.Module):
    def __init__(self, input_dim=399, embed_dim=384):
        self.spatial_layers = nn.Sequential(
            nn.Linear(399, 512),      # í‚¤í¬ì¸íŠ¸ ì••ì¶•
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 384),      # ì„ë² ë”© ì°¨ì›ìœ¼ë¡œ ë³€í™˜
            nn.LayerNorm(384),
            nn.Dropout(0.1)
        )
```

**ì—­í• **:
- í”„ë ˆì„ë³„ 133Ã—3 í‚¤í¬ì¸íŠ¸ë¥¼ 384ì°¨ì› ë²¡í„°ë¡œ ì••ì¶•
- ê³µê°„ì  íŒ¨í„´ ì¶”ì¶œ (ì†ì˜ ëª¨ì–‘, ì–¼êµ´ í‘œì •, ëª¸ì²´ ìì„¸)
- ì¶œë ¥: `[batch, seq_len, 384]`

### 3ï¸âƒ£ **ìœ„ì¹˜ ì¸ì½”ë”© (PositionalEncoding)**

**ë°©ì‹**: Sinusoidal Encoding
```python
PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))
```

**ì—­í• **:
- ì‹œê°„ì  ìœ„ì¹˜ ì •ë³´ ì œê³µ
- ìˆœì„œê°€ ì¤‘ìš”í•œ ìˆ˜í™” ë™ì‘ì˜ ì‹œí€€ìŠ¤ ì´í•´
- ìµœëŒ€ 500í”„ë ˆì„ ì§€ì›

### 4ï¸âƒ£ **Transformer Encoder (ì‹œê°„ì  íŒ¨í„´ í•™ìŠµ)**

**ì„¤ì •**:
- **ë ˆì´ì–´ ìˆ˜**: 6ê°œ
- **í—¤ë“œ ìˆ˜**: 8ê°œ (Multi-Head Attention)
- **í”¼ë“œí¬ì›Œë“œ ì°¨ì›**: 1024ì°¨ì›
- **ë“œë¡­ì•„ì›ƒ**: 0.1

**Self-Attention ë©”ì»¤ë‹ˆì¦˜**:
```python
# ê° í”„ë ˆì„ì´ ë‹¤ë¥¸ ëª¨ë“  í”„ë ˆì„ê³¼ì˜ ê´€ê³„ë¥¼ í•™ìŠµ
Attention(Q,K,V) = softmax(QK^T/âˆšd_k)V
```

**ì—­í• **:
- ì‹œê°„ì  ì˜ì¡´ì„± í•™ìŠµ (ìˆ˜í™” ë™ì‘ì˜ ì‹œì‘-ì§„í–‰-ë)
- ì¥ê±°ë¦¬ ì˜ì¡´ì„± í¬ì°© (ë¬¸ë§¥ì  ì´í•´)
- ë…¸ì´ì¦ˆ í”„ë ˆì„ í•„í„°ë§

### 5ï¸âƒ£ **ì¶œë ¥ ì „ëµ: í›ˆë ¨ vs ì¶”ë¡ **

#### ğŸ‹ï¸ **í›ˆë ¨ ëª¨ë“œ (Teacher Forcing)**
```python
def _forward_training(self, encoder_output, vocab_ids, vocab_masks):
    # Decoder ì…ë ¥ ì¤€ë¹„ (ì‹œì‘ í† í° ì¶”ê°€)
    decoder_input_ids = torch.cat([
        torch.zeros(batch_size, 1),  # <START> í† í°
        vocab_ids[:, :-1]           # ì •ë‹µ ë‹¨ì–´ë“¤ (í•œ ë‹¨ê³„ shifted)
    ], dim=1)
    
    # Transformer Decoderë¡œ ìˆœì°¨ ìƒì„± í•™ìŠµ
    decoder_output = self.transformer_decoder(...)
    return word_logits, boundary_logits, confidence_scores
```

#### âš¡ **ì¶”ë¡  ëª¨ë“œ (ì‹¤ì‹œê°„ ìµœì í™”)**
```python
def _forward_inference(self, encoder_output):
    # Decoder ì—†ì´ ê° í”„ë ˆì„ë³„ë¡œ ì§ì ‘ ë¶„ë¥˜
    word_logits = self.word_classifier(encoder_output)     # [batch, frames, 442]
    boundary_logits = self.boundary_detector(encoder_output) # [batch, frames, 3]
    confidence_scores = self.confidence_head(encoder_output) # [batch, frames, 1]
    return outputs
```

### 6ï¸âƒ£ **ì‹¤ì‹œê°„ ë””ì½”ë”© ìƒíƒœ ë¨¸ì‹ **

```python
class RealtimeDecoder:
    def __init__(self):
        self.state = "WAITING"  # WAITING â†’ IN_WORD â†’ COOLDOWN
        self.word_buffer = []
        self.confidence_buffer = []
```

**ìƒíƒœ ì „í™˜**:
1. **WAITING**: ìƒˆë¡œìš´ ìˆ˜í™” ì‹œì‘ ëŒ€ê¸°
   - START ê²½ê³„ ì‹ í˜¸ ëŒ€ê¸° (boundary_pred == 0)
2. **IN_WORD**: ìˆ˜í™” ë™ì‘ ì¤‘
   - í”„ë ˆì„ë³„ ì˜ˆì¸¡ì„ ë²„í¼ì— ëˆ„ì 
   - END ê²½ê³„ ì‹ í˜¸ ê°ì§€ ì‹œ ë‹¨ì–´ ì¶œë ¥
3. **COOLDOWN**: ì¤‘ë³µ ê°ì§€ ë°©ì§€ (10í”„ë ˆì„ ëŒ€ê¸°)

## ğŸ¯ ì¶”ë¡  ê³¼ì • ìƒì„¸ ë¶„ì„

### ì‹¤ì‹œê°„ í”„ë ˆì„ ì²˜ë¦¬
```python
for frame in video_stream:
    # 1. í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
    keypoints = RTMW_detector(frame)  # [133, 3]
    
    # 2. ì •ê·œí™”
    normalized = normalize_keypoints(keypoints)
    
    # 3. ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad():
        outputs = model(normalized.unsqueeze(0))
        
    # 4. ì‹¤ì‹œê°„ ë””ì½”ë”©
    word = realtime_decoder.process_frame_output(
        outputs['word_logits'][0],
        outputs['boundary_logits'][0], 
        outputs['confidence_scores'][0]
    )
    
    # 5. ë‹¨ì–´ ì¶œë ¥ (ìˆëŠ” ê²½ìš°)
    if word is not None:
        print(f"ê°ì§€ëœ ìˆ˜í™”: {vocabulary[word]}")
```

### í•µì‹¬ íŠ¹ì§•
1. **í”„ë ˆì„ ë ˆë²¨ ì²˜ë¦¬**: ê° í”„ë ˆì„ë§ˆë‹¤ ë…ë¦½ì  ì˜ˆì¸¡
2. **ê²½ê³„ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜**: START/END ì‹ í˜¸ë¡œ ë‹¨ì–´ êµ¬ë¶„
3. **ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§**: ë‚®ì€ ì‹ ë¢°ë„ ì˜ˆì¸¡ ì œì™¸
4. **ìƒíƒœ ê¸°ë°˜ ë””ì½”ë”©**: ì¤‘ë³µ/ì˜¤íƒì§€ ë°©ì§€

## ğŸ¨ ë°ì´í„° ì¦ê°• ì‹œìŠ¤í…œ

### êµ¬í˜„ëœ 4ê°€ì§€ ì¦ê°• ê¸°ë²•

#### 1. **ì¢Œìš° ë°˜ì „ (Horizontal Flip)**
```python
def _horizontal_flip(self, keypoints):
    flipped = keypoints.copy()
    flipped[:, :, 0] = 1.0 - flipped[:, :, 0]  # X ì¢Œí‘œ ë°˜ì „
    return flipped
```
- **í™•ë¥ **: 50% (ê¸°ë³¸ê°’)
- **íš¨ê³¼**: ì¢Œ/ìš° ë°©í–¥ì„±ì´ ë‹¤ë¥¸ ìˆ˜í™” ë³€í˜• ìƒì„±

#### 2. **íšŒì „ ë³€í™˜ (Rotation)**  
```python
def _rotate(self, keypoints, angle_degrees):
    # ì¤‘ì‹¬ì (0.5, 0.5) ê¸°ì¤€ íšŒì „
    cos_a, sin_a = math.cos(angle_rad), math.sin(angle_rad)
    x_rot = (x - 0.5) * cos_a - (y - 0.5) * sin_a + 0.5
    y_rot = (x - 0.5) * sin_a + (y - 0.5) * cos_a + 0.5
```
- **ë²”ìœ„**: Â±15ë„ (ê¸°ë³¸ê°’)
- **íš¨ê³¼**: ìì—°ìŠ¤ëŸ¬ìš´ ê°ë„ ë³€í™” ì‹œë®¬ë ˆì´ì…˜

#### 3. **í¬ê¸° ë³€í™˜ (Scaling)**
```python
def _scale(self, keypoints, scale_factor):
    # ì¤‘ì‹¬ì  ê¸°ì¤€ í¬ê¸° ì¡°ì ˆ
    scaled[:, :, 0] = (keypoints[:, :, 0] - 0.5) * scale + 0.5
    scaled[:, :, 1] = (keypoints[:, :, 1] - 0.5) * scale + 0.5
```
- **ë²”ìœ„**: 0.9~1.1ë°° (ê¸°ë³¸ê°’)
- **íš¨ê³¼**: ì¹´ë©”ë¼ ê±°ë¦¬ ë³€í™” ì‹œë®¬ë ˆì´ì…˜

#### 4. **ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ (Gaussian Noise)**
```python  
def _add_noise(self, keypoints):
    noise = np.random.normal(0, self.noise_std, keypoints.shape)
    return keypoints + noise
```
- **í‘œì¤€í¸ì°¨**: 0.005 (ê¸°ë³¸ê°’)
- **íš¨ê³¼**: í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ì˜¤ì°¨ ì‹œë®¬ë ˆì´ì…˜

### ì¦ê°• ì„¤ì • ë° ì‚¬ìš©ë²•
```python
# config.py ì„¤ì •
augmentation_config = {
    'enable_horizontal_flip': True,
    'horizontal_flip_prob': 0.5,
    'enable_rotation': True,
    'rotation_range': 15.0,
    'enable_scaling': True, 
    'scaling_range': (0.9, 1.1),
    'enable_noise': True,
    'noise_std': 0.005
}

# í›ˆë ¨ ì‹œì—ë§Œ ìë™ ì ìš©, ê²€ì¦ ì‹œ ë¹„í™œì„±í™”
```

## âš¡ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 1. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**
- **ë™ì  íŒ¨ë”©**: ë°°ì¹˜ ë‚´ ìµœëŒ€ ê¸¸ì´ë¡œë§Œ íŒ¨ë”©
- **ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…**: ë©”ëª¨ë¦¬ vs ê³„ì‚° íŠ¸ë ˆì´ë“œì˜¤í”„
- **ë°°ì¹˜ í¬ê¸° ìë™ ì¡°ì •**: XPU=48, CUDA=32, CPU=16

### 2. **ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”**
- **Decoder ìƒëµ**: ì¶”ë¡  ì‹œ ì§ì ‘ ë¶„ë¥˜ë¡œ ì§€ì—°ì‹œê°„ ìµœì†Œí™”
- **í”„ë ˆì„ ê±´ë„ˆë›°ê¸°**: ì—°ì† í”„ë ˆì„ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
- **ì„ê³„ê°’ ì¡°ì •**: ì •í™•ë„ vs ì‘ë‹µì„± ê· í˜•

### 3. **ë‹¤ì¤‘ ë””ë°”ì´ìŠ¤ ì§€ì›**
```python
# ë””ë°”ì´ìŠ¤ ìš°ì„ ìˆœìœ„: XPU > CUDA > CPU
device = detect_optimal_device()
model = model.to(device)

# ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” ì„¤ì • ìë™ ì ìš©
config = create_config(device_type=device)
```

## ğŸ”§ ê°œì„  ê°€ëŠ¥ ì˜ì—­ ë¶„ì„

### âœ… **í˜„ì¬ ê°•ì **
1. **ì‹¤ì‹œê°„ ì„±ëŠ¥**: Decoder ì—†ëŠ” ì§ì ‘ ë¶„ë¥˜ë¡œ ë¹ ë¥¸ ì¶”ë¡ 
2. **ë‹¤ì¤‘ ì¶œë ¥**: ë‹¨ì–´+ê²½ê³„+ì‹ ë¢°ë„ ë™ì‹œ ì˜ˆì¸¡
3. **ê°•ê±´í•œ ì¦ê°•**: 4ê°€ì§€ ì¦ê°•ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ  
4. **ë‹¤ì¤‘ ë””ë°”ì´ìŠ¤**: XPU/CUDA/CPU ì§€ì›

### âš ï¸ **ê°œì„  í¬ì¸íŠ¸**

#### 1. **ì‹œê°„ì  ì˜ì¡´ì„± ë¶€ì¡±**
**í˜„ì¬ ë¬¸ì œ**: ê° í”„ë ˆì„ ë…ë¦½ì  ë¶„ë¥˜ë¡œ ë‹¨ì–´ ê°„ ì—°ê²°ì„± ì œí•œ
**ê°œì„  ë°©ì•ˆ**:
```python
# LSTM ë˜ëŠ” Temporal Attention ì¶”ê°€
class TemporalContextLayer(nn.Module):
    def __init__(self, embed_dim):
        self.lstm = nn.LSTM(embed_dim, embed_dim//2, bidirectional=True)
        
    def forward(self, frame_features):
        # ì‹œê°„ì  ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        context_features, _ = self.lstm(frame_features)
        return context_features
```

#### 2. **ì–´íœ˜ í™•ì¥ì„±**
**í˜„ì¬ ë¬¸ì œ**: ê³ ì •ëœ 442ê°œ ì–´íœ˜, ìƒˆ ë‹¨ì–´ ì¶”ê°€ ì‹œ ì¬í›ˆë ¨ í•„ìš”
**ê°œì„  ë°©ì•ˆ**:
```python
# Few-shot Learning ë˜ëŠ” Meta-learning ë„ì…
class MetaLearningHead(nn.Module):
    def __init__(self):
        self.prototype_network = PrototypeNetwork()
        
    def add_new_word(self, support_samples, word_label):
        # ì ì€ ìƒ˜í”Œë¡œ ìƒˆë¡œìš´ ë‹¨ì–´ í•™ìŠµ
        prototype = self.prototype_network(support_samples)
        self.word_prototypes[word_label] = prototype
```

#### 3. **ì–‘ë°©í–¥ ì»¨í…ìŠ¤íŠ¸ í™œìš©**
**í˜„ì¬ ë¬¸ì œ**: ë‹¨ë°©í–¥ ì²˜ë¦¬ë¡œ ë¯¸ë˜ ì •ë³´ í™œìš© ë¶€ì¡±
**ê°œì„  ë°©ì•ˆ**:
```python
# Bidirectional Transformer ë˜ëŠ” Non-causal Attention
class BidirectionalEncoder(nn.Module):
    def __init__(self):
        self.forward_encoder = TransformerEncoder()
        self.backward_encoder = TransformerEncoder()
        
    def forward(self, x):
        forward_out = self.forward_encoder(x)
        backward_out = self.backward_encoder(torch.flip(x, dims=[1]))
        return torch.cat([forward_out, backward_out], dim=-1)
```

#### 4. **ë©€í‹°ëª¨ë‹¬ í™•ì¥**  
**í˜„ì¬ í•œê³„**: í¬ì¦ˆ ì •ë³´ë§Œ ì‚¬ìš©
**ê°œì„  ë°©ì•ˆ**:
```python
# RGB + Optical Flow + Audio í†µí•©
class MultiModalEncoder(nn.Module):
    def __init__(self):
        self.pose_encoder = SpatialEncoder()
        self.rgb_encoder = ResNet3D()
        self.audio_encoder = AudioCNN()
        self.fusion_layer = MultiModalFusion()
        
    def forward(self, pose, rgb, audio):
        pose_feat = self.pose_encoder(pose)
        rgb_feat = self.rgb_encoder(rgb) 
        audio_feat = self.audio_encoder(audio)
        return self.fusion_layer(pose_feat, rgb_feat, audio_feat)
```

## ğŸš€ ì‹¤í—˜ ë° í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
```bash
# ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
python debug_dataloader.py

# ì¦ê°• íš¨ê³¼ í™•ì¸  
python test_augmentation.py

# ëª¨ë¸ êµ¬ì¡° í™•ì¸
python sign_language_model.py

# ê°„ë‹¨í•œ í•™ìŠµ í…ŒìŠ¤íŠ¸
python train.py --config debug --epochs 3
```

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹
```bash
# ì‹¤ì‹œê°„ ì¶”ë¡  ì„±ëŠ¥ ì¸¡ì •
python realtime_inference.py --benchmark

# ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ ì¸¡ì •
python analyze_data.py --benchmark
```

### ì‹œê°í™” ë° ë¶„ì„
```bash
# TensorBoard ì‹¤í–‰
tensorboard --logdir=logs_xpu

# í•™ìŠµ ê³¡ì„  ë¶„ì„
python analyze_training_logs.py
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
mosu/
â”œâ”€â”€ sign_language_model.py      # ğŸ§  ë©”ì¸ ëª¨ë¸ (Seq2Seq Transformer)
â”œâ”€â”€ unified_pose_dataloader.py  # ğŸ“Š ë°ì´í„° ë¡œë” + ì¦ê°• ì‹œìŠ¤í…œ
â”œâ”€â”€ sign_language_trainer.py    # ğŸ‹ï¸ í•™ìŠµ ê´€ë¦¬ì
â”œâ”€â”€ config.py                   # âš™ï¸ ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ train.py                    # ğŸš€ í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ realtime_inference.py       # âš¡ ì‹¤ì‹œê°„ ì¶”ë¡ 
â”œâ”€â”€ data/                       # ğŸ“ ë°ì´í„° íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ sign_language_dataset_only_sen_lzf.h5
â”‚   â””â”€â”€ batch_SEN_*.h5
â”œâ”€â”€ checkpoints_*/              # ğŸ’¾ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â””â”€â”€ logs_*/                     # ğŸ“ˆ í•™ìŠµ ë¡œê·¸
```

---

## ğŸ¯ ê²°ë¡ 

í˜„ì¬ ìˆ˜í™” ì¸ì‹ ì‹œìŠ¤í…œì€ **ì‹¤ì‹œê°„ ì„±ëŠ¥ì— ìµœì í™”ëœ Sequence-to-Sequence Transformer**ë¡œ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

**í•µì‹¬ íŠ¹ì§•**:
- 133ê°œ í‚¤í¬ì¸íŠ¸ â†’ 384ì°¨ì› ì„ë² ë”© â†’ Transformer ì²˜ë¦¬
- í›ˆë ¨ ì‹œ Teacher Forcing, ì¶”ë¡  ì‹œ ì§ì ‘ ë¶„ë¥˜
- 4ê°€ì§€ ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ
- XPU/CUDA/CPU ë©€í‹° ë””ë°”ì´ìŠ¤ ì§€ì›

**ì£¼ìš” ê°œì„  ë°©í–¥**:
1. ì‹œê°„ì  ì»¨í…ìŠ¤íŠ¸ ê°•í™” (LSTM/Temporal Attention)
2. ì–´íœ˜ í™•ì¥ì„± (Few-shot Learning)
3. ì–‘ë°©í–¥ ì •ë³´ í™œìš© (Bidirectional Processing)
4. ë©€í‹°ëª¨ë‹¬ í™•ì¥ (RGB + Audio ì¶”ê°€)

í˜„ì¬ êµ¬ì¡°ëŠ” ì‹¤ì‹œê°„ ì²˜ë¦¬ì—ëŠ” ìš°ìˆ˜í•˜ì§€ë§Œ, ë³µì¡í•œ ë¬¸ë§¥ì´ë‚˜ ìƒˆë¡œìš´ ì–´íœ˜ì— ëŒ€í•œ ì ì‘ì„±ì—ì„œ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤.

---

*ìµœì¢… ì—…ë°ì´íŠ¸: 2025-08-10*  
*ëª¨ë¸ êµ¬ì¡° ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ ì™„ë£Œ*
