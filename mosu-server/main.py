#!/usr/bin/env python3
"""
MOSU ì‹¤ì‹œê°„ ìˆ˜í™” ì¸ì‹ ì„œë²„
- ì›¹ìº  ì…ë ¥ ìˆ˜ì‹ 
- RTMW í¬ì¦ˆ ì¶”ì •
- ìˆ˜í™” ì¸ì‹ ì¶”ë¡ 
- ì‹¤ì‹œê°„ ê²°ê³¼ ë°˜í™˜
"""

import asyncio
import cv2
import numpy as np
import torch
import time
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from collections import deque
import base64
import io
from PIL import Image

# FastAPI & WebSocket
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.requests import Request
from fastapi.responses import HTMLResponse
import uvicorn

# MMPose ê´€ë ¨
from mmpose.apis import init_model, inference_topdown

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sign_language_model import SequenceToSequenceSignModel, RealtimeDecoder

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
)
logger = logging.getLogger(__name__)

class RTMWPoseEstimator:
    """RTMW í¬ì¦ˆ ì¶”ì •ê¸°"""
    
    def __init__(self, 
                 rtmw_config: str = None,
                 rtmw_checkpoint: str = None,
                 device: str = "auto"):
        
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (pose-serverì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²½ë¡œì™€ ë™ì¼)
        if rtmw_config is None:
            rtmw_config = "configs/wholebody_2d_keypoint/rtmpose/cocktail14/rtmw-l_8xb320-270e_cocktail14-384x288.py"
        if rtmw_checkpoint is None:
            rtmw_checkpoint = "models/rtmw-dw-x-l_simcc-cocktail14_270e-384x288-f840f204_20231122.pth"
        
        self.rtmw_config = rtmw_config
        self.rtmw_checkpoint = rtmw_checkpoint
        self.device = self._determine_device(device)
        
        # PyTorch ë³´ì•ˆ ì„¤ì •
        self.original_load = torch.load
        torch.load = lambda *args, **kwargs: self.original_load(
            *args, **kwargs, weights_only=False
        ) if 'weights_only' not in kwargs else self.original_load(*args, **kwargs)
        
        self._initialize_model()
    
    def _determine_device(self, device: str) -> str:
        """ë””ë°”ì´ìŠ¤ ìë™ ê²°ì •"""
        if device == "auto":
            try:
                if torch.xpu.is_available():
                    return "xpu"
            except:
                pass
            
            if torch.cuda.is_available():
                return "cuda"
            
            return "cpu"
        return device
    
    def _initialize_model(self):
        """RTMW ëª¨ë¸ ì´ˆê¸°í™”"""
        logger.info(f"ğŸ”§ RTMW í¬ì¦ˆ ëª¨ë¸ ë¡œë”© ì¤‘... (ë””ë°”ì´ìŠ¤: {self.device})")
        start_time = time.time()
        
        try:
            # ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ ë”ë¯¸ í¬ì¦ˆ ì¶”ì •ê¸° ì‚¬ìš©
            if not Path(self.rtmw_config).exists() or not Path(self.rtmw_checkpoint).exists():
                logger.warning("âš ï¸ RTMW ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë”ë¯¸ í¬ì¦ˆ ì¶”ì •ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
                self.use_dummy = True
                self.pose_model = None
            else:
                self.pose_model = init_model(
                    config=self.rtmw_config,
                    checkpoint=self.rtmw_checkpoint,
                    device=self.device
                )
                self.use_dummy = False
            
            init_time = time.time() - start_time
            logger.info(f"âœ… í¬ì¦ˆ ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {init_time:.2f}ì´ˆ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ RTMW ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨, ë”ë¯¸ í¬ì¦ˆ ì¶”ì •ê¸° ì‚¬ìš©: {e}")
            self.use_dummy = True
            self.pose_model = None
    
    def estimate_pose(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ì´ë¯¸ì§€ì—ì„œ í¬ì¦ˆ ì¶”ì •"""
        if self.use_dummy:
            return self._dummy_pose_estimation(image)
        
        try:
            h, w = image.shape[:2]
            full_bbox = [0, 0, w, h]
            
            results = inference_topdown(
                model=self.pose_model,
                img=image,
                bboxes=[full_bbox],
                bbox_format='xyxy'
            )
            
            if results and len(results) > 0:
                keypoints = results[0].pred_instances.keypoints[0]
                scores = results[0].pred_instances.keypoint_scores[0]
                
                if isinstance(keypoints, torch.Tensor):
                    keypoints = keypoints.cpu().numpy()
                if isinstance(scores, torch.Tensor):
                    scores = scores.cpu().numpy()
                
                return keypoints, scores
            else:
                return self._dummy_pose_estimation(image)
                
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ ì¶”ì • ì‹¤íŒ¨: {e}")
            return self._dummy_pose_estimation(image)
    
    def _dummy_pose_estimation(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ë”ë¯¸ í¬ì¦ˆ ì¶”ì • (ê°œë°œìš©)"""
        h, w = image.shape[:2]
        
        # ë”ë¯¸ í‚¤í¬ì¸íŠ¸ ìƒì„± (133ê°œ)
        keypoints = np.random.rand(133, 2) * np.array([w, h])
        scores = np.random.rand(133) * 0.8 + 0.2  # 0.2-1.0 ë²”ìœ„
        
        return keypoints, scores

class SignLanguageInferencer:
    """ìˆ˜í™” ì¸ì‹ ì¶”ë¡ ê¸°"""
    
    def __init__(self, 
                 model_path: str,
                 device: str = "auto",
                 confidence_threshold: float = 0.7):
        
        self.device = torch.device(device if device != "auto" else "cuda" if torch.cuda.is_available() else "cpu")
        self.confidence_threshold = confidence_threshold
        
        self._load_model(model_path)
        self._initialize_components()
        
        logger.info(f"âœ… ìˆ˜í™” ì¸ì‹ ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {self.device})")
    
    def _load_model(self, model_path: str):
        """ìˆ˜í™” ì¸ì‹ ëª¨ë¸ ë¡œë“œ"""
        model_path = Path(model_path)
        if not model_path.exists():
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        
        try:
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            
            # Vocabulary ì¶”ì¶œ
            if 'vocab_words' in checkpoint:
                self.words = checkpoint['vocab_words']
                self.word_to_id = {word: i for i, word in enumerate(self.words)}
            else:
                # ê¸°ë³¸ vocabulary
                self.words = [f"ë‹¨ì–´_{i:03d}" for i in range(442)]
                self.word_to_id = {word: i for i, word in enumerate(self.words)}
            
            vocab_size = len(self.words)
            
            # ëª¨ë¸ ìƒì„±
            self.model = SequenceToSequenceSignModel(
                vocab_size=vocab_size,
                embed_dim=256,
                num_encoder_layers=6,
                num_decoder_layers=4,
                num_heads=8
            )
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.device)
            self.model.eval()
            
            logger.info(f"ğŸ“š ìˆ˜í™” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: vocabulary {vocab_size}ê°œ ë‹¨ì–´")
            
        except Exception as e:
            logger.error(f"âŒ ìˆ˜í™” ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _initialize_components(self):
        """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        self.window_size = 60  # 2ì´ˆ (30fps ê¸°ì¤€)
        self.pose_buffer = deque(maxlen=self.window_size)
        
        self.decoder = RealtimeDecoder(
            vocab_size=len(self.words),
            confidence_threshold=self.confidence_threshold
        )
        
        # í†µê³„
        self.inference_times = deque(maxlen=100)
        self.detected_words = []
    
    @torch.no_grad()
    def process_pose(self, keypoints: np.ndarray, scores: np.ndarray) -> Optional[str]:
        """í¬ì¦ˆ ë°ì´í„° ì²˜ë¦¬ ë° ìˆ˜í™” ì¸ì‹"""
        # í¬ì¦ˆ íŠ¹ì§• ìƒì„± [133, 3] (x, y, score)
        pose_features = np.zeros((133, 3), dtype=np.float32)
        pose_features[:, :2] = keypoints
        pose_features[:, 2] = scores
        
        # ë²„í¼ì— ì¶”ê°€
        self.pose_buffer.append(pose_features)
        
        # ìµœì†Œ í”„ë ˆì„ ìˆ˜ í™•ì¸
        if len(self.pose_buffer) < 30:  # 1ì´ˆ ìµœì†Œ
            return None
        
        start_time = time.time()
        
        # ìœˆë„ìš° ë°ì´í„° ì¤€ë¹„
        window_data = np.array(list(self.pose_buffer))  # [frames, 133, 3]
        
        # íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°
        if len(window_data) < self.window_size:
            padding = np.zeros((self.window_size - len(window_data), 133, 3), dtype=np.float32)
            window_data = np.concatenate([padding, window_data], axis=0)
        
        # í…ì„œ ë³€í™˜ ë° ì¶”ë¡ 
        input_tensor = torch.from_numpy(window_data).unsqueeze(0).to(self.device)
        
        try:
            outputs = self.model(input_tensor)
            
            # í˜„ì¬ í”„ë ˆì„ì˜ ì¶œë ¥
            word_logits = outputs['word_logits'][0, -1]
            boundary_logits = outputs['boundary_logits'][0, -1]
            confidence_score = outputs['confidence_scores'][0, -1]
            
            # ì‹¤ì‹œê°„ ë””ì½”ë” ì²˜ë¦¬
            result = self.decoder.process_frame_output(word_logits, boundary_logits, confidence_score)
            
            inference_time = time.time() - start_time
            self.inference_times.append(inference_time)
            
            if result is not None:
                word = self.words[result] if result < len(self.words) else f"ë‹¨ì–´_{result}"
                self.detected_words.append(word)
                logger.info(f"ğŸ¯ ìˆ˜í™” ì¸ì‹: {word}")
                return word
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ ìˆ˜í™” ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return None

class MosuServer:
    """MOSU í†µí•© ì„œë²„"""
    
    def __init__(self, 
                 model_path: str,
                 device: str = "auto",
                 host: str = "0.0.0.0",
                 port: int = 8000):
        
        self.host = host
        self.port = port
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.pose_estimator = RTMWPoseEstimator(device=device)
        self.sign_inferencer = SignLanguageInferencer(model_path, device)
        
        # FastAPI ì•± ì„¤ì •
        self.app = FastAPI(title="MOSU Sign Language Recognition Server")
        self.app.mount("/static", StaticFiles(directory="static"), name="static")
        
        # WebSocket ì—°ê²° ê´€ë¦¬
        self.connections: List[WebSocket] = []
        
        self.setup_routes()
        
        logger.info(f"ğŸš€ MOSU ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   - ì„œë²„ ì£¼ì†Œ: {host}:{port}")
        logger.info(f"   - Vocabulary: {len(self.sign_inferencer.words)}ê°œ ë‹¨ì–´")
    
    def setup_routes(self):
        """ë¼ìš°íŠ¸ ì„¤ì •"""
        
        @self.app.get("/", response_class=HTMLResponse)
        async def index(request: Request):
            """ë©”ì¸ í˜ì´ì§€"""
            return self.get_index_html()
        
        @self.app.get("/health")
        async def health_check():
            """í—¬ìŠ¤ ì²´í¬"""
            return {
                "status": "healthy",
                "pose_device": self.pose_estimator.device,
                "sign_device": str(self.sign_inferencer.device),
                "vocab_size": len(self.sign_inferencer.words),
                "connections": len(self.connections)
            }
        
        @self.app.get("/stats")
        async def get_stats():
            """í†µê³„ ì •ë³´"""
            pose_times = getattr(self.pose_estimator, 'inference_times', [])
            sign_times = list(self.sign_inferencer.inference_times)
            
            return {
                "connections": len(self.connections),
                "detected_words": self.sign_inferencer.detected_words[-10:],  # ìµœê·¼ 10ê°œ
                "pose_estimation": {
                    "count": len(pose_times),
                    "avg_time": np.mean(pose_times) if pose_times else 0
                },
                "sign_recognition": {
                    "count": len(sign_times),
                    "avg_time": np.mean(sign_times) if sign_times else 0
                }
            }
        
        @self.app.websocket("/ws")
        async def websocket_endpoint(websocket: WebSocket):
            """WebSocket ì—”ë“œí¬ì¸íŠ¸"""
            await websocket.accept()
            self.connections.append(websocket)
            logger.info(f"ğŸ”— ìƒˆ ì—°ê²°: ì´ {len(self.connections)}ê°œ")
            
            try:
                while True:
                    # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ ë°ì´í„° ìˆ˜ì‹ 
                    data = await websocket.receive_json()
                    
                    if data["type"] == "frame":
                        # Base64 ì´ë¯¸ì§€ ë””ì½”ë”©
                        image_data = base64.b64decode(data["image"].split(",")[1])
                        image = Image.open(io.BytesIO(image_data))
                        image_np = np.array(image)
                        
                        # RGB to BGR (OpenCV)
                        if len(image_np.shape) == 3:
                            image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
                        
                        # í¬ì¦ˆ ì¶”ì •
                        keypoints, scores = self.pose_estimator.estimate_pose(image_np)
                        
                        # ìˆ˜í™” ì¸ì‹
                        detected_word = self.sign_inferencer.process_pose(keypoints, scores)
                        
                        # ê²°ê³¼ ì „ì†¡
                        response = {
                            "type": "result",
                            "timestamp": time.time(),
                            "pose": {
                                "keypoints": keypoints.tolist(),
                                "scores": scores.tolist()
                            },
                            "sign": {
                                "word": detected_word,
                                "confidence": float(scores.mean()) if scores is not None else 0.0
                            }
                        }
                        
                        await websocket.send_json(response)
                        
            except WebSocketDisconnect:
                self.connections.remove(websocket)
                logger.info(f"ğŸ”Œ ì—°ê²° ì¢…ë£Œ: ì´ {len(self.connections)}ê°œ")
            except Exception as e:
                logger.error(f"âŒ WebSocket ì˜¤ë¥˜: {e}")
                if websocket in self.connections:
                    self.connections.remove(websocket)
    
    def get_index_html(self) -> str:
        """ë©”ì¸ í˜ì´ì§€ HTML"""
        return """
        <!DOCTYPE html>
        <html>
        <head>
            <title>MOSU ì‹¤ì‹œê°„ ìˆ˜í™” ì¸ì‹</title>
            <meta charset="UTF-8">
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; background-color: #f0f0f0; }
                .container { max-width: 1200px; margin: 0 auto; }
                .header { text-align: center; margin-bottom: 30px; }
                .video-container { display: flex; gap: 20px; margin-bottom: 20px; }
                .video-box { flex: 1; }
                video, canvas { width: 100%; max-width: 640px; height: 480px; border: 2px solid #ddd; border-radius: 10px; }
                .controls { text-align: center; margin: 20px 0; }
                button { padding: 10px 20px; margin: 5px; font-size: 16px; cursor: pointer; border: none; border-radius: 5px; }
                .start-btn { background-color: #4CAF50; color: white; }
                .stop-btn { background-color: #f44336; color: white; }
                .results { background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
                .word-display { font-size: 24px; font-weight: bold; color: #2196F3; margin: 10px 0; }
                .stats { display: flex; gap: 20px; margin-top: 20px; }
                .stat-box { flex: 1; background: #e3f2fd; padding: 15px; border-radius: 5px; text-align: center; }
                #detected-words { min-height: 100px; background: #f5f5f5; padding: 10px; border-radius: 5px; }
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ¤² MOSU ì‹¤ì‹œê°„ ìˆ˜í™” ì¸ì‹</h1>
                    <p>ì›¹ìº ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ìˆ˜í™” ì¸ì‹ ì‹œìŠ¤í…œ</p>
                </div>
                
                <div class="video-container">
                    <div class="video-box">
                        <h3>ğŸ“¹ ì›¹ìº  ì…ë ¥</h3>
                        <video id="video" autoplay muted></video>
                    </div>
                    <div class="video-box">
                        <h3>ğŸ¯ í¬ì¦ˆ ì¶”ì •</h3>
                        <canvas id="canvas"></canvas>
                    </div>
                </div>
                
                <div class="controls">
                    <button class="start-btn" onclick="startCamera()">ğŸ“¹ ì¹´ë©”ë¼ ì‹œì‘</button>
                    <button class="stop-btn" onclick="stopCamera()">â¹ï¸ ì •ì§€</button>
                    <button onclick="clearResults()">ğŸ—‘ï¸ ê²°ê³¼ ì´ˆê¸°í™”</button>
                </div>
                
                <div class="results">
                    <h3>ğŸ¯ ì¸ì‹ ê²°ê³¼</h3>
                    <div class="word-display" id="current-word">ëŒ€ê¸° ì¤‘...</div>
                    
                    <div class="stats">
                        <div class="stat-box">
                            <h4>ğŸ“Š ì—°ê²° ìƒíƒœ</h4>
                            <div id="connection-status">ì—°ê²° ì•ˆë¨</div>
                        </div>
                        <div class="stat-box">
                            <h4>âš¡ ì²˜ë¦¬ ì†ë„</h4>
                            <div id="fps">0 FPS</div>
                        </div>
                        <div class="stat-box">
                            <h4>ğŸ¯ ì‹ ë¢°ë„</h4>
                            <div id="confidence">0%</div>
                        </div>
                    </div>
                    
                    <h4>ğŸ“ ê°ì§€ëœ ë‹¨ì–´ë“¤</h4>
                    <div id="detected-words"></div>
                </div>
            </div>
            
            <script>
                let video = document.getElementById('video');
                let canvas = document.getElementById('canvas');
                let ctx = canvas.getContext('2d');
                let ws = null;
                let stream = null;
                let sending = false;
                let frameCount = 0;
                let lastFpsUpdate = Date.now();
                let detectedWords = [];
                
                // WebSocket ì—°ê²°
                function connectWebSocket() {
                    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                    const wsUrl = `${protocol}//${window.location.host}/ws`;
                    
                    ws = new WebSocket(wsUrl);
                    
                    ws.onopen = function() {
                        document.getElementById('connection-status').textContent = 'âœ… ì—°ê²°ë¨';
                        console.log('WebSocket ì—°ê²° ì„±ê³µ');
                    };
                    
                    ws.onmessage = function(event) {
                        const data = JSON.parse(event.data);
                        
                        if (data.type === 'result') {
                            // í¬ì¦ˆ ì‹œê°í™”
                            drawPose(data.pose);
                            
                            // ìˆ˜í™” ê²°ê³¼ í‘œì‹œ
                            if (data.sign.word) {
                                document.getElementById('current-word').textContent = data.sign.word;
                                addDetectedWord(data.sign.word);
                            }
                            
                            // ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
                            const confidence = Math.round(data.sign.confidence * 100);
                            document.getElementById('confidence').textContent = confidence + '%';
                            
                            // FPS ê³„ì‚°
                            frameCount++;
                            const now = Date.now();
                            if (now - lastFpsUpdate > 1000) {
                                const fps = Math.round(frameCount * 1000 / (now - lastFpsUpdate));
                                document.getElementById('fps').textContent = fps + ' FPS';
                                frameCount = 0;
                                lastFpsUpdate = now;
                            }
                        }
                    };
                    
                    ws.onclose = function() {
                        document.getElementById('connection-status').textContent = 'âŒ ì—°ê²° ëŠê¹€';
                        console.log('WebSocket ì—°ê²° ì¢…ë£Œ');
                    };
                    
                    ws.onerror = function(error) {
                        console.error('WebSocket ì˜¤ë¥˜:', error);
                        document.getElementById('connection-status').textContent = 'âŒ ì˜¤ë¥˜';
                    };
                }
                
                // ì¹´ë©”ë¼ ì‹œì‘
                async function startCamera() {
                    try {
                        stream = await navigator.mediaDevices.getUserMedia({
                            video: { width: 640, height: 480 }
                        });
                        video.srcObject = stream;
                        
                        canvas.width = 640;
                        canvas.height = 480;
                        
                        if (!ws || ws.readyState === WebSocket.CLOSED) {
                            connectWebSocket();
                        }
                        
                        // í”„ë ˆì„ ì „ì†¡ ì‹œì‘
                        setTimeout(sendFrame, 100); // 10 FPSë¡œ ì œí•œ
                        
                    } catch (error) {
                        console.error('ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜:', error);
                        alert('ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
                    }
                }
                
                // ì¹´ë©”ë¼ ì •ì§€
                function stopCamera() {
                    if (stream) {
                        stream.getTracks().forEach(track => track.stop());
                        stream = null;
                    }
                    sending = false;
                    
                    if (ws) {
                        ws.close();
                    }
                }
                
                // í”„ë ˆì„ ì „ì†¡
                function sendFrame() {
                    if (!stream || !ws || ws.readyState !== WebSocket.OPEN || sending) {
                        if (stream) setTimeout(sendFrame, 100);
                        return;
                    }
                    
                    sending = true;
                    
                    // ì„ì‹œ ìº”ë²„ìŠ¤ì— ë¹„ë””ì˜¤ í”„ë ˆì„ ê·¸ë¦¬ê¸°
                    const tempCanvas = document.createElement('canvas');
                    tempCanvas.width = 640;
                    tempCanvas.height = 480;
                    const tempCtx = tempCanvas.getContext('2d');
                    tempCtx.drawImage(video, 0, 0, 640, 480);
                    
                    // Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ì†¡
                    const dataUrl = tempCanvas.toDataURL('image/jpeg', 0.7);
                    
                    ws.send(JSON.stringify({
                        type: 'frame',
                        image: dataUrl
                    }));
                    
                    sending = false;
                    setTimeout(sendFrame, 100); // 10 FPS
                }
                
                // í¬ì¦ˆ ì‹œê°í™”
                function drawPose(pose) {
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                    
                    const keypoints = pose.keypoints;
                    const scores = pose.scores;
                    
                    // í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
                    ctx.fillStyle = 'red';
                    for (let i = 0; i < keypoints.length; i++) {
                        if (scores[i] > 0.5) {
                            const x = keypoints[i][0];
                            const y = keypoints[i][1];
                            ctx.beginPath();
                            ctx.arc(x, y, 3, 0, 2 * Math.PI);
                            ctx.fill();
                        }
                    }
                }
                
                // ê°ì§€ëœ ë‹¨ì–´ ì¶”ê°€
                function addDetectedWord(word) {
                    if (!detectedWords.includes(word)) {
                        detectedWords.push(word);
                        updateDetectedWordsDisplay();
                    }
                }
                
                // ê°ì§€ëœ ë‹¨ì–´ í‘œì‹œ ì—…ë°ì´íŠ¸
                function updateDetectedWordsDisplay() {
                    const container = document.getElementById('detected-words');
                    container.innerHTML = detectedWords.map(word => 
                        `<span style="display: inline-block; margin: 5px; padding: 5px 10px; background: #2196F3; color: white; border-radius: 15px;">${word}</span>`
                    ).join('');
                }
                
                // ê²°ê³¼ ì´ˆê¸°í™”
                function clearResults() {
                    detectedWords = [];
                    document.getElementById('current-word').textContent = 'ëŒ€ê¸° ì¤‘...';
                    document.getElementById('detected-words').innerHTML = '';
                    document.getElementById('confidence').textContent = '0%';
                }
                
                // í˜ì´ì§€ ë¡œë“œ ì‹œ WebSocket ì—°ê²°
                window.onload = function() {
                    connectWebSocket();
                };
                
                // í˜ì´ì§€ ì¢…ë£Œ ì‹œ ì •ë¦¬
                window.onbeforeunload = function() {
                    stopCamera();
                };
            </script>
        </body>
        </html>
        """
    
    def run(self):
        """ì„œë²„ ì‹¤í–‰"""
        logger.info(f"\nğŸš€ MOSU ì„œë²„ ì‹œì‘")
        logger.info(f"   - ì£¼ì†Œ: http://{self.host}:{self.port}")
        logger.info(f"   - í—¬ìŠ¤ì²´í¬: http://{self.host}:{self.port}/health")
        logger.info(f"   - í†µê³„: http://{self.host}:{self.port}/stats")
        logger.info(f"   - Ctrl+Cë¡œ ì¢…ë£Œ")
        
        try:
            uvicorn.run(
                self.app,
                host=self.host,
                port=self.port,
                log_level="info"
            )
        except KeyboardInterrupt:
            logger.info("\nâ¹ï¸ MOSU ì„œë²„ ì¢…ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ì„œë²„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="MOSU Real-time Sign Language Recognition Server")
    parser.add_argument("--model", type=str, 
                       default="../mosumodel/best_model_stage_1.pt",
                       help="ìˆ˜í™” ì¸ì‹ ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--device", type=str, default="auto",
                       choices=["auto", "cpu", "cuda", "xpu"],
                       help="ì¶”ë¡  ë””ë°”ì´ìŠ¤")
    parser.add_argument("--host", type=str, default="0.0.0.0",
                       help="ì„œë²„ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--port", type=int, default=8000,
                       help="ì„œë²„ í¬íŠ¸")
    
    args = parser.parse_args()
    
    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    model_path = Path(args.model)
    if not model_path.exists():
        logger.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    try:
        server = MosuServer(
            model_path=str(model_path),
            device=args.device,
            host=args.host,
            port=args.port
        )
        
        server.run()
        
    except Exception as e:
        logger.error(f"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main()
