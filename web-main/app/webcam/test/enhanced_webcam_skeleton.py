import cv2
import os
import time
import datetime
import glob
import requests
import json
import numpy as np

# COCO Wholebody ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ì •ë³´
COCO_WHOLEBODY_SKELETON = [
    # Body (0~16)
    [0, 1], [0, 2], [1, 3], [2, 4],
    [5, 6], [5, 7], [7, 9], [6, 8], [8, 10],
    [5, 11], [6, 12], [11, 12], [11, 13], [13, 15], [12, 14], [14, 16],

    # Left Hand (91~111)
    [91, 92], [92, 93], [93, 94], [94, 95],         # Thumb
    [91, 96], [96, 97], [97, 98], [98, 99],         # Index
    [91, 100], [100, 101], [101, 102], [102, 103],  # Middle
    [91, 104], [104, 105], [105, 106], [106, 107],  # Ring
    [91, 108], [108, 109], [109, 110], [110, 111],  # Pinky

    # Right Hand (112~132)
    [112, 113], [113, 114], [114, 115], [115, 116],      # Thumb
    [112, 117], [117, 118], [118, 119], [119, 120],      # Index
    [112, 121], [121, 122], [122, 123], [123, 124],      # Middle
    [112, 125], [125, 126], [126, 127], [127, 128],      # Ring
    [112, 129], [129, 130], [130, 131], [131, 132],      # Pinky
]

def draw_keypoints_wholebody_on_frame(frame, keypoints, scores, threshold=2.0):
    """í”„ë ˆì„ì— wholebody í‚¤í¬ì¸íŠ¸ì™€ ìŠ¤ì¼ˆë ˆí†¤ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜ (ì„œë²„ì—ì„œ ì´ë¯¸  ì¢Œí‘œ ë³€í™˜ë¨)"""
    num_points = 133
    
    print(f"ğŸ”§ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì‹œì‘")
    print(f"  - í”„ë ˆì„ í¬ê¸°: {frame.shape[1]}x{frame.shape[0]}")
    print(f"  - í‚¤í¬ì¸íŠ¸ ê°œìˆ˜: {len(keypoints)}")
    print(f"  - ìŠ¤ì½”ì–´ ê°œìˆ˜: {len(scores)}")

    # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° (ì„œë²„ì—ì„œ ì´ë¯¸ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜ë¨)
    drawn_points = 0
    for idx in range(min(num_points, len(keypoints), len(scores))):
        if 17 <= idx <= 22:  # ë°œ keypoint ë¬´ì‹œ
            continue
        if scores[idx] > threshold:
            x, y = keypoints[idx][:2]
            # í”„ë ˆì„ ê²½ê³„ í™•ì¸
            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:
                cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 0), -1)
                drawn_points += 1

    print(f"âœ… ê·¸ë ¤ì§„ í‚¤í¬ì¸íŠ¸: {drawn_points}ê°œ")

    # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
    drawn_lines = 0
    for idx1, idx2 in COCO_WHOLEBODY_SKELETON:
        if 17 <= idx1 <= 22 or 17 <= idx2 <= 22:  # ë°œ keypoint í¬í•¨ëœ ì—°ê²° ë¬´ì‹œ
            continue
        if (idx1 < len(scores) and idx2 < len(scores) and 
            scores[idx1] > threshold and scores[idx2] > threshold):
            x1, y1 = keypoints[idx1][:2]
            x2, y2 = keypoints[idx2][:2]
            
            # í”„ë ˆì„ ê²½ê³„ í™•ì¸
            if (0 <= x1 < frame.shape[1] and 0 <= y1 < frame.shape[0] and
                0 <= x2 < frame.shape[1] and 0 <= y2 < frame.shape[0]):
                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                drawn_lines += 1
    
    print(f"âœ… ê·¸ë ¤ì§„ ì—°ê²°ì„ : {drawn_lines}ê°œ")

def draw_sign_recognition_result(frame, sign_result, confidence_threshold=0.6):
    """í”„ë ˆì„ì— ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜"""
    if not sign_result:
        return
    
    try:
        h, w = frame.shape[:2]
        
        # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        overlay = frame.copy()
        box_height = 120
        cv2.rectangle(overlay, (10, 10), (w-10, box_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ì œëª© í…ìŠ¤íŠ¸
        cv2.putText(frame, "Sign Recognition Result", (20, 35), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        sign_prediction = sign_result.get('sign_prediction')
        if sign_prediction and sign_prediction.get('confidence', 0) >= confidence_threshold:
            predicted_class = sign_prediction.get('predicted_class', 'Unknown')
            confidence = sign_prediction.get('confidence', 0)
            
            # ì˜ˆì¸¡ëœ ìˆ˜ì–´ì™€ ì‹ ë¢°ë„ í‘œì‹œ
            result_text = f"Sign: {predicted_class}"
            confidence_text = f"Confidence: {confidence:.2f}"
            
            cv2.putText(frame, result_text, (20, 65), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(frame, confidence_text, (20, 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        else:
            # ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš°
            cv2.putText(frame, "No sign detected or low confidence", (20, 65), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (128, 128, 128), 2)
        
        # MediaPipe ê°ì§€ ìƒíƒœ í‘œì‹œ
        mediapipe_results = sign_result.get('mediapipe_results', {})
        hand_detected = mediapipe_results.get('hand_detected', False)
        pose_detected = mediapipe_results.get('pose_detected', False)
        
        status_text = f"Hand: {'âœ“' if hand_detected else 'âœ—'}  Pose: {'âœ“' if pose_detected else 'âœ—'}"
        cv2.putText(frame, status_text, (w-200, 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
    except Exception as e:
        print(f"âŒ ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ í‘œì‹œ ì˜¤ë¥˜: {e}")

class WebcamCapture:
    def __init__(self):
        self.cap = None
        self.recording = False
        self.video_writer = None
        self.capturing_images = False
        self.realtime_translate = False
        self.realtime_fps = 0
        self.capture_folder = None
        self.capture_image_count = 0
        self.video_folder = "./captured_videos"
        self.image_folder = "./captured_images"
        self.video_count = 0
        self.image_count = 0
        self.w = 640
        self.h = 480
        self.fps = 10
        self.last_server_result = ""
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™” ê´€ë ¨ ë³€ìˆ˜ë“¤
        self.show_skeleton = False
        self.last_pose_data = None  # ë§ˆì§€ë§‰ í¬ì¦ˆ ë°ì´í„° ì €ì¥
        self.pose_threshold = 2.0

        # ìˆ˜ì–´ ì¸ì‹ ê´€ë ¨ ë³€ìˆ˜ë“¤ ì¶”ê°€
        self.show_sign_recognition = False
        self.sign_recognition_mode = False  # ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ í™œì„±í™”
        self.last_sign_result = None  # ë§ˆì§€ë§‰ ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼
        self.sign_confidence_threshold = 0.6  # ìˆ˜ì–´ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’
        self.use_mediapipe_server = True  # MediaPipe ì„œë²„ ì‚¬ìš© ì—¬ë¶€

        # í´ë” ìƒì„±
        os.makedirs(self.video_folder, exist_ok=True)
        os.makedirs(self.image_folder, exist_ok=True)

    def initialize_camera(self):
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        if self.cap is None or not self.cap.isOpened():
            self.cap = cv2.VideoCapture(0)
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.w)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.h)
            self.fps = self.cap.get(cv2.CAP_PROP_FPS) or 30
        return self.cap.isOpened()
    
    def release_camera(self):
        """ì¹´ë©”ë¼ í•´ì œ"""
        if self.cap:
            self.cap.release()
            self.cap = None
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None
    
    def toggle_skeleton_display(self):
        """ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ í† ê¸€"""
        self.show_skeleton = not self.show_skeleton
        status = f"ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ: {'ì¼œì§' if self.show_skeleton else 'êº¼ì§'}"
        print(f"ğŸ”§ {status}")
        return status
    
    def toggle_sign_recognition_display(self):
        """ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ í‘œì‹œ í† ê¸€"""
        self.show_sign_recognition = not self.show_sign_recognition
        status = f"ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ í‘œì‹œ: {'ì¼œì§' if self.show_sign_recognition else 'êº¼ì§'}"
        print(f"ğŸ”§ {status}")
        return status
    
    def toggle_sign_recognition_mode(self):
        """ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ í† ê¸€"""
        self.sign_recognition_mode = not self.sign_recognition_mode
        if self.sign_recognition_mode:
            self.show_sign_recognition = True  # ìë™ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œë„ í™œì„±í™”
        status = f"ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ: {'ì¼œì§' if self.sign_recognition_mode else 'êº¼ì§'}"
        print(f"ğŸ”§ {status}")
        return status
    
    def set_pose_threshold(self, threshold):
        """í¬ì¦ˆ ì„ê³„ê°’ ì„¤ì •"""
        self.pose_threshold = threshold
        return f"í¬ì¦ˆ ì„ê³„ê°’: {threshold}"
    
    def set_sign_confidence_threshold(self, threshold):
        """ìˆ˜ì–´ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •"""
        self.sign_confidence_threshold = threshold
        return f"ìˆ˜ì–´ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’: {threshold}"
    
    def start_realtime(self):
        """ì´ë¯¸ì§€ ì‹¤ì‹œê°„ ë²ˆì—­ ì‹œì‘"""
        if not self.realtime_translate:
            self.realtime_translate = True
            self.realtime_fps = 0
            self.last_server_result = ""
            return f"ì‹¤ì‹œê°„ ë²ˆì—­ ì‹œì‘"
        return "ì´ë¯¸ ì‹¤ì‹œê°„ ë²ˆì—­ ì¤‘ì…ë‹ˆë‹¤"

    def stop_realtime(self):
        """ì´ë¯¸ì§€ ì‹¤ì‹œê°„ ë²ˆì—­ ì¢…ë£Œ"""
        if self.realtime_translate:
            self.realtime_translate = False
            self.realtime_fps = 0
            return f"ì‹¤ì‹œê°„ ë²ˆì—­ ì¢…ë£Œ"
        return "ì´ë¯¸ ì‹¤ì‹œê°„ ë²ˆì—­ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤."

    def start_capture_images(self):
        """ì´ë¯¸ì§€ ì—°ì† ì €ì¥ ì‹œì‘"""
        if not self.capturing_images:
            now = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
            self.capture_folder = os.path.join("captured_datas", now)
            os.makedirs(self.capture_folder, exist_ok=True)
            self.capturing_images = True
            self.capture_image_count = 0
            return f"ì´ë¯¸ì§€ ìº¡ì²˜ ì‹œì‘: {self.capture_folder}"
        return "ì´ë¯¸ ì´ë¯¸ì§€ ìº¡ì²˜ ì¤‘ì…ë‹ˆë‹¤"

    def stop_capture_images(self):
        """ì´ë¯¸ì§€ ì—°ì† ì €ì¥ ì¢…ë£Œ"""
        if self.capturing_images:
            self.capturing_images = False
            folder = self.capture_folder
            self.capture_folder = None
            return f"ì´ë¯¸ì§€ ìº¡ì²˜ ì¢…ë£Œ: {folder}"
        return "ì´ë¯¸ì§€ ìº¡ì²˜ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤"

    def capture_frame(self):
        """í”„ë ˆì„ ìº¡ì²˜"""
        if not self.initialize_camera():
            return None
        
        ret, frame = self.cap.read()
        if ret:
            # ì‹¤ì‹œê°„ ë²ˆì—­ ëª¨ë“œì—ì„œ ì„œë²„ë¡œ ì›ë³¸ ì´ë¯¸ì§€ ì „ì†¡
            if self.realtime_translate:
                self.send_frame_to_server(frame)
            
            # ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œê°€ í™œì„±í™”ëœ ê²½ìš° MediaPipe ì„œë²„ë¡œ ì „ì†¡
            if self.sign_recognition_mode:
                self.send_frame_for_sign_recognition(frame)
            
            # í˜„ì¬ ìƒíƒœ ì¶œë ¥ (ë§¤ 10í”„ë ˆì„ë§ˆë‹¤)
            if self.realtime_fps % 10 == 0:
                print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ - ì‹¤ì‹œê°„ë²ˆì—­: {self.realtime_translate}, ìˆ˜ì–´ì¸ì‹: {self.sign_recognition_mode}, ìŠ¤ì¼ˆë ˆí†¤í‘œì‹œ: {self.show_skeleton}, ìˆ˜ì–´ê²°ê³¼í‘œì‹œ: {self.show_sign_recognition}")
            
            # ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œê°€ í™œì„±í™”ë˜ì–´ ìˆê³  í¬ì¦ˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ë¦¬ê¸°
            if self.show_skeleton and self.last_pose_data:
                try:
                    keypoints = self.last_pose_data.get('keypoints', [])
                    scores = self.last_pose_data.get('scores', [])
                    
                    print(f"ğŸ¨ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì‹œë„ - í‚¤í¬ì¸íŠ¸: {len(keypoints)}, ìŠ¤ì½”ì–´: {len(scores)}")
                    
                    if keypoints and scores:
                        draw_keypoints_wholebody_on_frame(
                            frame, keypoints, scores, self.pose_threshold
                        )
                        print("âœ… ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì™„ë£Œ")
                    else:
                        print("âŒ í‚¤í¬ì¸íŠ¸ ë˜ëŠ” ìŠ¤ì½”ì–´ê°€ ë¹„ì–´ìˆìŒ")
                        
                except Exception as e:
                    print(f"ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
            elif self.show_skeleton:
                print("â³ ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ í™œì„±í™”ë¨, í¬ì¦ˆ ë°ì´í„° ëŒ€ê¸° ì¤‘...")
            
            # ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ í‘œì‹œ
            if self.show_sign_recognition and self.last_sign_result:
                try:
                    draw_sign_recognition_result(
                        frame, self.last_sign_result, self.sign_confidence_threshold
                    )
                    print("âœ… ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ í‘œì‹œ ì™„ë£Œ")
                except Exception as e:
                    print(f"ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ í‘œì‹œ ì˜¤ë¥˜: {e}")
            
            # ë…¹í™” ì¤‘ì´ë©´ ë¹„ë””ì˜¤ì— ì €ì¥
            if self.recording and self.video_writer:
                self.video_writer.write(frame)
            # ì´ë¯¸ì§€ ì—°ì† ì €ì¥ ì¤‘ì´ë©´ íŒŒì¼ë¡œ ì €ì¥
            elif self.capturing_images and self.capture_folder:
                self.capture_image_count += 1
                image_path = os.path.join(
                    self.capture_folder, f"img_{self.capture_image_count:04d}.jpg"
                )
                cv2.imwrite(image_path, frame)

            return frame
        return None
    
    def save_image(self, save_skeleton=False, save_sign_result=False):
        """ì´ë¯¸ì§€ ì €ì¥"""
        if not self.initialize_camera():
            return None
        
        ret, frame = self.cap.read()
        if ret:
            # ìŠ¤ì¼ˆë ˆí†¤ ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆê³  í¬ì¦ˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ë¦¬ê¸°
            if save_skeleton and self.last_pose_data:
                try:
                    keypoints = self.last_pose_data.get('keypoints', [])
                    scores = self.last_pose_data.get('scores', [])
                    
                    if keypoints and scores:
                        draw_keypoints_wholebody_on_frame(
                            frame, keypoints, scores, self.pose_threshold
                        )
                except Exception as e:
                    print(f"ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
            
            # ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ì €ì¥ ì˜µì…˜
            if save_sign_result and self.last_sign_result:
                try:
                    draw_sign_recognition_result(
                        frame, self.last_sign_result, self.sign_confidence_threshold
                    )
                except Exception as e:
                    print(f"ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
    
    def start_recording(self):
        """ë¹„ë””ì˜¤ ë…¹í™” ì‹œì‘"""
        if not self.recording:
            self.video_count += 1
            video_path = f"{self.video_folder}/record_{self.video_count}.avi"
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            self.video_writer = cv2.VideoWriter(video_path, fourcc, self.fps, (self.w, self.h))
            self.recording = True
            return f"ë…¹í™” ì‹œì‘: {video_path}"
        return "ì´ë¯¸ ë…¹í™” ì¤‘ì…ë‹ˆë‹¤"
    
    def stop_recording(self):
        """ë¹„ë””ì˜¤ ë…¹í™” ì¢…ë£Œ"""
        if self.recording:
            self.recording = False
            if self.video_writer:
                self.video_writer.release()
                self.video_writer = None
            return "ë…¹í™” ì¢…ë£Œ"
        return "ë…¹í™” ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤"
    
    def generate_frames(self):
        """ìŠ¤íŠ¸ë¦¬ë°ìš© í”„ë ˆì„ ìƒì„±"""
        # fpsê°€ 0ì´ê±°ë‚˜ Noneì´ë©´ ê¸°ë³¸ê°’ 30fps ì‚¬ìš©
        fps = self.fps if self.fps and self.fps > 0 else 30
        target_interval = 1.0 / fps

        while True:
            start = time.time()
            frame = self.capture_frame()
            if frame is not None:
                # JPEGë¡œ ì¸ì½”ë”©
                ret, buffer = cv2.imencode('.jpg', frame)
                if ret:
                    frame_bytes = buffer.tobytes()
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            elapsed = time.time() - start
            sleep_time = max(0, target_interval - elapsed)
            if sleep_time > 0:
                time.sleep(sleep_time)

    def send_frame_for_sign_recognition(self, frame):
        """MediaPipe ìˆ˜ì–´ ì¸ì‹ì„ ìœ„í•´ í”„ë ˆì„ì„ ì„œë²„ë¡œ ì „ì†¡"""
        try:
            # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
            ret, buffer = cv2.imencode('.jpg', frame)
            if not ret:
                print("âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨ (ìˆ˜ì–´ ì¸ì‹)")
                return
                
            frame_bytes = buffer.tobytes()
            
            print(f"ğŸ“¤ ìˆ˜ì–´ ì¸ì‹ì„ ìœ„í•´ ì„œë²„ë¡œ ì´ë¯¸ì§€ ì „ì†¡")
            
            files = {'image': (f'sign_{self.realtime_fps}.jpg', frame_bytes, 'image/jpeg')}
            data = {
                'frame_id': str(self.realtime_fps),
                'confidence_threshold': str(self.sign_confidence_threshold),
                'include_features': 'false'  # íŠ¹ì§• ë°ì´í„°ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
            }
            
            resp = requests.post(
                "http://192.168.100.135:5000/recognize_sign",  # ìƒˆë¡œìš´ ìˆ˜ì–´ ì¸ì‹ ì—”ë“œí¬ì¸íŠ¸
                files=files,
                data=data,
                timeout=10
            )
            
            # ì„œë²„ ì‘ë‹µ ì²˜ë¦¬ ë° ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ì €ì¥
            if resp.status_code == 200:
                print("âœ… ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì „ì†¡ ì„±ê³µ")
                try:
                    # ì„œë²„ ì‘ë‹µ ë‚´ìš© í™•ì¸
                    print(f"ğŸ“¥ ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì‘ë‹µ ë‚´ìš©: {resp.text[:300]}...")
                    
                    # JSON íŒŒì‹±
                    response_data = resp.json()
                    print(f"ğŸ“‹ ìˆ˜ì–´ ì¸ì‹ ì‘ë‹µ í‚¤ë“¤: {list(response_data.keys())}")
                    
                    # ì˜¤ë¥˜ ì²´í¬
                    if 'error' in response_data:
                        print(f"âš ï¸ ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì˜¤ë¥˜: {response_data['error']}")
                        return
                    
                    # ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ë¶„ì„
                    sign_prediction = response_data.get('sign_prediction')
                    mediapipe_results = response_data.get('mediapipe_results', {})
                    
                    print(f"ğŸ“Š ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ë¶„ì„:")
                    print(f"  - ì† ê°ì§€: {mediapipe_results.get('hand_detected', False)}")
                    print(f"  - í¬ì¦ˆ ê°ì§€: {mediapipe_results.get('pose_detected', False)}")
                    
                    if sign_prediction:
                        confidence = sign_prediction.get('confidence', 0)
                        predicted_class = sign_prediction.get('predicted_class', 'Unknown')
                        print(f"  - ì˜ˆì¸¡ëœ ìˆ˜ì–´: {predicted_class}")
                        print(f"  - ì‹ ë¢°ë„: {confidence:.3f}")
                        
                        if confidence >= self.sign_confidence_threshold:
                            print(f"âœ… ë†’ì€ ì‹ ë¢°ë„ë¡œ ìˆ˜ì–´ ì¸ì‹ë¨!")
                        else:
                            print(f"âš ï¸ ì‹ ë¢°ë„ê°€ ì„ê³„ê°’({self.sign_confidence_threshold}) ë¯¸ë§Œ")
                    else:
                        print(f"âŒ ìˆ˜ì–´ ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ")
                    
                    # ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ì €ì¥
                    self.last_sign_result = response_data
                    print(f"âœ… ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ì—…ë°ì´íŠ¸ë¨!")
                    
                except json.JSONDecodeError as e:
                    print(f"âŒ ìˆ˜ì–´ ì¸ì‹ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    print(f"ì‘ë‹µì´ JSONì´ ì•„ë‹˜: {resp.text}")
                except Exception as e:
                    print(f"âŒ ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            else:
                print(f"âŒ ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {resp.status_code}")
                
        except Exception as e:
            print(f"âŒ ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

    def send_frame_to_server(self, frame):
        """ì„œë²„ë¡œ ì›ë³¸ í”„ë ˆì„ ì „ì†¡ (ì„œë²„ì—ì„œ YOLO ì²˜ë¦¬)"""
        self.realtime_fps += 1 
        print(f"self.realtime_fps : {self.realtime_fps}")
        
        # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
        ret, buffer = cv2.imencode('.jpg', frame)
        if not ret:
            print("âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
            return
            
        frame_bytes = buffer.tobytes()
        
        try:
            print(f"ğŸ“¤ ì„œë²„ë¡œ ì›ë³¸ ì´ë¯¸ì§€ ì „ì†¡")
            
            files = {'image': (f'{self.realtime_fps}.jpg', frame_bytes, 'image/jpeg')}
            data = {'frame_id': str(self.realtime_fps)}
            
            resp = requests.post(
                "http://192.168.100.135:5000/estimate_pose",
                files=files,
                data=data,
                timeout=10
            )
            
            # ì„œë²„ ì‘ë‹µ ì²˜ë¦¬ ë° í¬ì¦ˆ ë°ì´í„° ì €ì¥
            if resp.status_code == 200:
                print("âœ… ì„œë²„ ì „ì†¡ ì„±ê³µ")
                try:
                    # ì„œë²„ ì‘ë‹µ ë‚´ìš© í™•ì¸
                    print(f"ğŸ“¥ ì„œë²„ ì‘ë‹µ ë‚´ìš©: {resp.text[:200]}...")
                    
                    # JSON íŒŒì‹±
                    response_data = resp.json()
                    print(f"ğŸ“‹ íŒŒì‹±ëœ ì‘ë‹µ í‚¤ë“¤: {list(response_data.keys())}")
                    
                    # ì˜¤ë¥˜ ì²´í¬
                    if 'error' in response_data:
                        print(f"âš ï¸ ì„œë²„ ì˜¤ë¥˜: {response_data['error']}")
                        return
                    
                    # í‚¤í¬ì¸íŠ¸ ë° ìŠ¤ì½”ì–´ ì¶”ì¶œ
                    keypoints = response_data.get('keypoints', [])
                    scores = response_data.get('scores', [])
                    person_box = response_data.get('person_box', [])
                    
                    if keypoints and scores:
                        # í‚¤í¬ì¸íŠ¸ ë°ì´í„° ë¶„ì„
                        print(f"ğŸ“Š í‚¤í¬ì¸íŠ¸ ë°ì´í„° ë¶„ì„:")
                        print(f"  - í‚¤í¬ì¸íŠ¸ ê°œìˆ˜: {len(keypoints)}")
                        print(f"  - ìŠ¤ì½”ì–´ ê°œìˆ˜: {len(scores)}")
                        
                        # í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ë²”ìœ„ í™•ì¸ (ì´ë¯¸ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜ë¨)
                        if len(keypoints) > 0:
                            x_coords = [kp[0] for kp in keypoints if len(kp) >= 2]
                            y_coords = [kp[1] for kp in keypoints if len(kp) >= 2]
                            if x_coords and y_coords:
                                print(f"  - X ì¢Œí‘œ ë²”ìœ„: {min(x_coords):.1f} ~ {max(x_coords):.1f}")
                                print(f"  - Y ì¢Œí‘œ ë²”ìœ„: {min(y_coords):.1f} ~ {max(y_coords):.1f}")
                        
                        # ìŠ¤ì½”ì–´ ë²”ìœ„ í™•ì¸
                        if len(scores) > 0:
                            print(f"  - ìŠ¤ì½”ì–´ ë²”ìœ„: {min(scores):.2f} ~ {max(scores):.2f}")
                            high_score_count = sum(1 for s in scores if s > self.pose_threshold)
                            print(f"  - ì„ê³„ê°’({self.pose_threshold}) ì´ìƒ ìŠ¤ì½”ì–´: {high_score_count}ê°œ")
                        
                        # ê²€ì¶œëœ ì‚¬ëŒ ì •ë³´
                        if person_box:
                            print(f"  - ê²€ì¶œëœ ì‚¬ëŒ ë°•ìŠ¤: {person_box[:4]} (ì‹ ë¢°ë„: {person_box[4]:.2f})")
                        
                        self.last_pose_data = {
                            'keypoints': keypoints,
                            'scores': scores,
                            'person_box': person_box
                        }
                        print(f"âœ… í¬ì¦ˆ ë°ì´í„° ì—…ë°ì´íŠ¸ë¨!")
                    else:
                        print(f"âŒ í‚¤í¬ì¸íŠ¸ ë˜ëŠ” ìŠ¤ì½”ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    print(f"ì‘ë‹µì´ JSONì´ ì•„ë‹˜: {resp.text}")
                except Exception as e:
                    print(f"âŒ ì„œë²„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            else:
                print(f"âŒ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {resp.status_code}")
                
            self.last_server_result = f"{self.realtime_fps}-ì„œë²„ ê²°ê³¼"
            
        except Exception as e:
            print(f"âŒ ì‹¤ì‹œê°„ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

    def process_latest_folder_images(self):
        """ê°€ì¥ ìµœê·¼ í´ë”ì˜ ì´ë¯¸ì§€ë¥¼ ì„œë²„ë¡œ ì „ì†¡"""
        base_dir = "captured_datas"
        if not os.path.exists(base_dir):
            return "ì €ì¥ëœ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        folders = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
        if not folders:
            return "ì €ì¥ëœ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        latest_folder = max(folders, key=os.path.getmtime)
        images = sorted(glob.glob(os.path.join(latest_folder, "*.jpg")))
        send_count = 0
        
        for img_path in images:
            frame = cv2.imread(img_path)
            if frame is None:
                continue
            
            # ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
            ret, buffer = cv2.imencode('.jpg', frame)
            if not ret:
                print(f"âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {img_path}")
                continue
            
            image_bytes = buffer.tobytes()
            
            # ì„œë²„ë¡œ ì „ì†¡
            try:
                files = {'image': (os.path.basename(img_path), image_bytes, 'image/jpeg')}
                data = {'frame_id': os.path.basename(img_path)}
                
                resp = requests.post(
                    "http://192.168.100.135:5000/estimate_pose",
                    files=files,
                    data=data,
                    timeout=10
                )
                
                if resp.status_code == 200:
                    send_count += 1
                    print(f"âœ… ì„œë²„ë¡œ ì „ì†¡ ì„±ê³µ: {send_count}, {img_path}")
                else:
                    print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {resp.status_code} {resp.text}")
                    
            except Exception as e:
                print(f"âŒ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {os.path.basename(img_path)} - {e}")
        
        return f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {len(images)}ê°œ ì´ë¯¸ì§€ ì¤‘ {send_count}ê°œ ì„œë²„ ì „ì†¡ ì„±ê³µ"

    def get_status_info(self):
        """í˜„ì¬ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        status = {
            'realtime_translate': self.realtime_translate,
            'sign_recognition_mode': self.sign_recognition_mode,
            'show_skeleton': self.show_skeleton,
            'show_sign_recognition': self.show_sign_recognition,
            'recording': self.recording,
            'capturing_images': self.capturing_images,
            'pose_threshold': self.pose_threshold,
            'sign_confidence_threshold': self.sign_confidence_threshold,
            'has_pose_data': self.last_pose_data is not None,
            'has_sign_result': self.last_sign_result is not None,
            'fps': self.fps,
            'frame_size': f"{self.w}x{self.h}"
        }
        
        # ìµœê·¼ ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ ì •ë³´ ì¶”ê°€
        if self.last_sign_result:
            sign_prediction = self.last_sign_result.get('sign_prediction')
            if sign_prediction:
                status['last_sign'] = {
                    'predicted_class': sign_prediction.get('predicted_class'),
                    'confidence': sign_prediction.get('confidence'),
                    'above_threshold': sign_prediction.get('confidence', 0) >= self.sign_confidence_threshold
                }
            
            mediapipe_results = self.last_sign_result.get('mediapipe_results', {})
            status['mediapipe_status'] = {
                'hand_detected': mediapipe_results.get('hand_detected', False),
                'pose_detected': mediapipe_results.get('pose_detected', False)
            }
        
        return status

    def test_sign_recognition_with_image(self, image_path):
        """íŠ¹ì • ì´ë¯¸ì§€ë¡œ ìˆ˜ì–´ ì¸ì‹ í…ŒìŠ¤íŠ¸"""
        if not os.path.exists(image_path):
            return f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}"
        
        frame = cv2.imread(image_path)
        if frame is None:
            return f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}"
        
        try:
            # ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
            ret, buffer = cv2.imencode('.jpg', frame)
            if not ret:
                return "ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨"
                
            frame_bytes = buffer.tobytes()
            
            files = {'image': (os.path.basename(image_path), frame_bytes, 'image/jpeg')}
            data = {
                'frame_id': os.path.basename(image_path),
                'confidence_threshold': str(self.sign_confidence_threshold),
                'include_features': 'false'
            }
            
            resp = requests.post(
                "http://192.168.100.135:5000/recognize_sign",
                files=files,
                data=data,
                timeout=15
            )
            
            if resp.status_code == 200:
                response_data = resp.json()
                
                # ê²°ê³¼ ì €ì¥
                self.last_sign_result = response_data
                
                # ê²°ê³¼ ì •ë³´ êµ¬ì„±
                result_info = {
                    'success': True,
                    'image_path': image_path,
                    'mediapipe_results': response_data.get('mediapipe_results', {}),
                    'sign_prediction': response_data.get('sign_prediction'),
                    'processing_times': response_data.get('processing_times', {})
                }
                
                return result_info
            else:
                return {
                    'success': False,
                    'error': f"ì„œë²„ ì˜¤ë¥˜: {resp.status_code}",
                    'response': resp.text[:200]
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': f"ìš”ì²­ ì‹¤íŒ¨: {str(e)}"
            }

# ì›¹ìº  ì œì–´ë¥¼ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜ë“¤
def print_controls():
    """ì¡°ì‘ë²• ì¶œë ¥"""
    print("\n" + "="*60)
    print("ğŸ¥ í–¥ìƒëœ ì›¹ìº  ì œì–´ ì‹œìŠ¤í…œ")
    print("="*60)
    print("ê¸°ë³¸ ì¡°ì‘ë²•:")
    print("  - ì‹¤ì‹œê°„ ë²ˆì—­: start_realtime() / stop_realtime()")
    print("  - ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ: toggle_sign_recognition_mode()")
    print("  - ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ: toggle_skeleton_display()")
    print("  - ìˆ˜ì–´ ê²°ê³¼ í‘œì‹œ: toggle_sign_recognition_display()")
    print("")
    print("ì„¤ì • ì¡°ì •:")
    print("  - í¬ì¦ˆ ì„ê³„ê°’: set_pose_threshold(ê°’)")
    print("  - ìˆ˜ì–´ ì‹ ë¢°ë„ ì„ê³„ê°’: set_sign_confidence_threshold(ê°’)")
    print("")
    print("ë…¹í™”/ìº¡ì²˜:")
    print("  - ë¹„ë””ì˜¤ ë…¹í™”: start_recording() / stop_recording()")
    print("  - ì´ë¯¸ì§€ ìº¡ì²˜: start_capture_images() / stop_capture_images()")
    print("")
    print("í…ŒìŠ¤íŠ¸:")
    print("  - ì´ë¯¸ì§€ ìˆ˜ì–´ ì¸ì‹ í…ŒìŠ¤íŠ¸: test_sign_recognition_with_image('ê²½ë¡œ')")
    print("  - ìƒíƒœ í™•ì¸: get_status_info()")
    print("="*60)

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ì›¹ìº  ìº¡ì²˜ ê°ì²´ ìƒì„±
    webcam = WebcamCapture()
    
    print_controls()
    
    # ì˜ˆì‹œ ì‚¬ìš©ë²•
    print("\nğŸš€ ì›¹ìº  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    print("ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•˜ì„¸ìš”:")
    print("webcam.toggle_sign_recognition_mode()  # ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ ì¼œê¸°")
    print("webcam.toggle_skeleton_display()       # ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ ì¼œê¸°")
    print("webcam.start_realtime()               # ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì‹¤í–‰
    try:
        print("\nğŸ“¹ ì›¹ìº  í…ŒìŠ¤íŠ¸ ì‹œì‘ (5ì´ˆê°„)")
        for i in range(50):  # ì•½ 5ì´ˆê°„ í…ŒìŠ¤íŠ¸
            frame = webcam.capture_frame()
            if frame is not None:
                # ì—¬ê¸°ì„œ cv2.imshow()ë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ë©´ì— í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
                # cv2.imshow('Webcam', frame)
                # if cv2.waitKey(1) & 0xFF == ord('q'):
                #     break
                pass
            time.sleep(0.1)
        
        print("âœ… ì›¹ìº  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    
    finally:
        webcam.release_camera()
        print("ğŸ”§ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")