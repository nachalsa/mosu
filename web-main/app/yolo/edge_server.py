import cv2
import numpy as np
import requests
import time
import json
import argparse
from typing import List, Optional, Tuple
from pathlib import Path
import logging
from collections import deque

class EdgeServer:
    """ì—£ì§€ ì„œë²„ - ì›¹ìº  ìº¡ì²˜ + YOLO ê²€ì¶œ + í¬ë¡­ + ì „ì†¡"""
    
    def __init__(self, 
                 pose_server_url: str,
                 camera_id: int = 0,
                 window_size: Tuple[int, int] = (1280, 720),
                 jpeg_quality: int = 85,
                 max_fps: int = 30):
        
        self.pose_server_url = pose_server_url.rstrip('/')
        self.camera_id = camera_id
        self.window_size = window_size
        self.jpeg_quality = jpeg_quality
        self.max_fps = max_fps
        
        # YOLO ê²€ì¶œê¸° ì´ˆê¸°í™”
        self.detector = EdgeYOLODetector()
        
        # ì›¹ìº  ì´ˆê¸°í™”
        self.cap = None
        self.init_camera()
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.fps_history = deque(maxlen=30)
        self.frame_count = 0
        
        print(f"âœ… ì—£ì§€ ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - í¬ì¦ˆ ì„œë²„: {self.pose_server_url}")
        print(f"   - ì¹´ë©”ë¼: {camera_id}")
        print(f"   - í•´ìƒë„: {window_size}")
        print(f"   - JPEG í’ˆì§ˆ: {jpeg_quality}%")
    
    def init_camera(self):
        """ì›¹ìº  ì´ˆê¸°í™”"""
        print(f"ğŸ“¹ ì›¹ìº  ì—°ê²° ì¤‘... (ì¹´ë©”ë¼ ID: {self.camera_id})")
        
        self.cap = cv2.VideoCapture(self.camera_id)
        if not self.cap.isOpened():
            raise RuntimeError(f"âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨ (ì¹´ë©”ë¼ ID: {self.camera_id})")
        
        # ì›¹ìº  ì„¤ì •
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.window_size[0])
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.window_size[1])
        self.cap.set(cv2.CAP_PROP_FPS, self.max_fps)
        
        # ì‹¤ì œ ì›¹ìº  í•´ìƒë„ í™•ì¸
        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        print(f"âœ… ì›¹ìº  ì—°ê²° ì„±ê³µ: {actual_width}x{actual_height}, {actual_fps:.1f}fps")
    
    def send_crop_to_pose_server(self, crop_image: np.ndarray, bbox: List[float], frame_id: int) -> Optional[dict]:
        """í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ í¬ì¦ˆ ì„œë²„ë¡œ ì „ì†¡"""
        try:
            # JPEG ì¸ì½”ë”©
            ret, jpeg_data = cv2.imencode('.jpg', crop_image, 
                                        [cv2.IMWRITE_JPEG_QUALITY, self.jpeg_quality])
            if not ret:
                return None
            
            # ìš”ì²­ ë°ì´í„° ì¤€ë¹„
            files = {'image': ('crop.jpg', jpeg_data.tobytes(), 'image/jpeg')}
            data = {
                'frame_id': frame_id,
                'bbox': json.dumps(bbox),
                'timestamp': time.time()
            }
            
            # POST ìš”ì²­
            response = requests.post(
                f"{self.pose_server_url}/estimate_pose",
                files=files,
                data=data,
                timeout=5.0
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"âš ï¸ í¬ì¦ˆ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except requests.RequestException as e:
            print(f"âš ï¸ í¬ì¦ˆ ì„œë²„ í†µì‹  ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return None
    
    def visualize_results(self, image: np.ndarray, person_boxes: List[List[float]], 
                         pose_results: List[dict]) -> np.ndarray:
        """ê²°ê³¼ ì‹œê°í™”"""
        vis_image = image.copy()
        
        # ê²€ì¶œëœ ë°”ìš´ë”©ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        for i, bbox in enumerate(person_boxes):
            x1, y1, x2, y2 = map(int, bbox)
            color = (0, 255, 0) if i == 0 else (255, 0, 255)
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)
            cv2.putText(vis_image, f"Person {i+1}", (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # í¬ì¦ˆ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° (ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜ í•„ìš”)
        for i, pose_result in enumerate(pose_results):
            if pose_result and 'keypoints' in pose_result:
                keypoints = np.array(pose_result['keypoints'])
                scores = np.array(pose_result['scores'])
                
                # í¬ë¡­ ì´ë¯¸ì§€ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                if i < len(person_boxes):
                    bbox = person_boxes[i]
                    # ê°„ë‹¨í•œ ìŠ¤ì¼€ì¼ë§ (ì‹¤ì œë¡œëŠ” ì•„í•€ ë³€í™˜ ì—­ë³€í™˜ í•„ìš”)
                    bbox_w = bbox[2] - bbox[0]
                    bbox_h = bbox[3] - bbox[1]
                    
                    for j, (kpt, score) in enumerate(zip(keypoints, scores)):
                        if score > 0.3:
                            # í¬ë¡­ ì¢Œí‘œ(288x384)ë¥¼ ì›ë³¸ ë°”ìš´ë”©ë°•ìŠ¤ ì¢Œí‘œë¡œ ë³€í™˜
                            x = int(bbox[0] + (kpt[0] / 288.0) * bbox_w)
                            y = int(bbox[1] + (kpt[1] / 384.0) * bbox_h)
                            
                            if 0 <= x < vis_image.shape[1] and 0 <= y < vis_image.shape[0]:
                                if score > 0.8:
                                    kpt_color = (0, 255, 0)    # ë†’ì€ ì‹ ë¢°ë„: ì´ˆë¡
                                elif score > 0.6:
                                    kpt_color = (0, 255, 255)  # ì¤‘ê°„ ì‹ ë¢°ë„: ë…¸ë‘
                                else:
                                    kpt_color = (0, 0, 255)    # ë‚®ì€ ì‹ ë¢°ë„: ë¹¨ê°•
                                
                                cv2.circle(vis_image, (x, y), 3, kpt_color, -1)
        
        # ì„±ëŠ¥ ì •ë³´ í‘œì‹œ
        if self.fps_history:
            avg_fps = np.mean(self.fps_history)
            cv2.putText(vis_image, f"Edge FPS: {avg_fps:.1f}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        cv2.putText(vis_image, f"YOLO11L Edge Server", 
                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(vis_image, f"Pose Server: {self.pose_server_url.split('://')[-1]}", 
                   (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(vis_image, f"Detections: {len(person_boxes)}", 
                   (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        return vis_image
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        print(f"\nğŸš€ ì—£ì§€ ì„œë²„ ì‹¤í–‰ ì‹œì‘")
        print(f"ğŸ® ì¡°ì‘ë²•:")
        print(f"   - ESC: ì¢…ë£Œ")
        print(f"   - S: ìŠ¤í¬ë¦°ìƒ·")
        print(f"   - SPACE: ì¼ì‹œì •ì§€/ì¬ìƒ")
        
        paused = False
        screenshot_count = 0
        
        try:
            while True:
                if not paused:
                    ret, frame = self.cap.read()
                    if not ret:
                        print("âŒ í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨")
                        break
                    
                    start_time = time.time()
                    
                    # 1. YOLO ê²€ì¶œ
                    person_boxes = self.detector.detect_persons(frame)
                    
                    # 2. ê° ì‚¬ëŒì— ëŒ€í•´ í¬ë¡­ + í¬ì¦ˆ ì„œë²„ë¡œ ì „ì†¡
                    pose_results = []
                    for i, bbox in enumerate(person_boxes):
                        crop_image = self.detector.crop_person_image_rtmw(frame, bbox)
                        if crop_image is not None:
                            # í¬ì¦ˆ ì„œë²„ë¡œ ì „ì†¡
                            pose_result = self.send_crop_to_pose_server(
                                crop_image, bbox, self.frame_count * 1000 + i
                            )
                            pose_results.append(pose_result)
                        else:
                            pose_results.append(None)
                    
                    # 3. FPS ê³„ì‚°
                    process_time = time.time() - start_time
                    fps = 1.0 / process_time if process_time > 0 else 0
                    self.fps_history.append(fps)
                    
                    # 4. ì‹œê°í™”
                    vis_frame = self.visualize_results(frame, person_boxes, pose_results)
                    self.frame_count += 1
                
                # í™”ë©´ í‘œì‹œ
                cv2.imshow('YOLO Edge Server', vis_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                
                if key == 27:  # ESC
                    break
                elif key == ord('s') or key == ord('S'):  # ìŠ¤í¬ë¦°ìƒ·
                    screenshot_name = f"edge_screenshot_{screenshot_count:04d}.jpg"
                    cv2.imwrite(screenshot_name, vis_frame)
                    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_name}")
                    screenshot_count += 1
                elif key == ord(' '):  # ì¼ì‹œì •ì§€/ì¬ìƒ
                    paused = not paused
                    print(f"â¸ï¸ {'ì¼ì‹œì •ì§€' if paused else 'ì¬ìƒ'}")
                
                # ì£¼ê¸°ì  í†µê³„ ì¶œë ¥
                if self.frame_count % 60 == 0 and self.frame_count > 0:
                    avg_fps = np.mean(self.fps_history) if self.fps_history else 0
                    print(f"ğŸ“Š í”„ë ˆì„ {self.frame_count}: {avg_fps:.1f}fps, "
                          f"{len(person_boxes)}ëª… ê²€ì¶œ")
                    
        except KeyboardInterrupt:
            print("\nâ¹ï¸ ì‚¬ìš©ìê°€ ì—£ì§€ ì„œë²„ë¥¼ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        
        finally:
            self.cleanup()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        
        if self.fps_history:
            avg_fps = np.mean(self.fps_history)
            print(f"\nğŸ“Š ì—£ì§€ ì„œë²„ ì™„ë£Œ:")
            print(f"   - ì²˜ë¦¬ëœ í”„ë ˆì„: {self.frame_count}")
            print(f"   - í‰ê·  FPS: {avg_fps:.1f}")
