
import cv2
import numpy as np
from typing import List, Optional, Tuple
from pathlib import Path
from collections import deque

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    print("âš ï¸ ultralytics ë¯¸ì„¤ì¹˜ - pip install ultralytics")
    YOLO_AVAILABLE = False

class EdgeYOLODetector:
    """ì—£ì§€ ë””ë°”ì´ìŠ¤ìš© YOLO ê²€ì¶œê¸°"""
    
    def __init__(self, 
                 yolo_model: str = "yolo11l.pt",
                 conf_thresh: float = 0.4,
                 iou_thresh: float = 0.6,
                 max_det: int = 50,
                 img_size: int = 832):
        
        if not YOLO_AVAILABLE:
            raise ImportError("ultralyticsê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install ultralytics")
        
        self.conf_thresh = conf_thresh
        self.iou_thresh = iou_thresh
        self.max_det = max_det
        self.img_size = img_size
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        print(f"ðŸ”§ YOLO11L ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = YOLO(yolo_model)
        print(f"âœ… YOLO11L ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    
    def detect_persons(self, image: np.ndarray) -> List[List[float]]:
        """ì‚¬ëžŒ ê²€ì¶œ"""
        try:
            results = self.model(
                image,
                conf=self.conf_thresh,
                iou=self.iou_thresh,
                max_det=self.max_det,
                classes=[0],  # ì‚¬ëžŒ í´ëž˜ìŠ¤ë§Œ
                verbose=False,
                imgsz=self.img_size
            )
            
            person_boxes = []
            for result in results:
                boxes = result.boxes
                if boxes is not None and len(boxes) > 0:
                    person_coords = boxes.xyxy
                    person_confs = boxes.conf
                    
                    # ì‹ ë¢°ë„ ìž¬í•„í„°ë§
                    conf_mask = person_confs >= self.conf_thresh
                    if conf_mask.any():
                        filtered_boxes = person_coords[conf_mask]
                        filtered_confs = person_confs[conf_mask]
                        
                        # numpy ë³€í™˜
                        if hasattr(filtered_boxes, 'cpu'):
                            filtered_boxes = filtered_boxes.cpu().numpy()
                            filtered_confs = filtered_confs.cpu().numpy()
                        
                        # ì‹ ë¢°ë„ìˆœ ì •ë ¬
                        sorted_indices = np.argsort(filtered_confs)[::-1]
                        sorted_boxes = filtered_boxes[sorted_indices]
                        
                        person_boxes.extend(sorted_boxes.tolist())
            
            return person_boxes
            
        except Exception as e:
            print(f"âŒ YOLO ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def crop_person_image_rtmw(self, image: np.ndarray, bbox: List[float]) -> Optional[np.ndarray]:
        """RTMW ë°©ì‹ìœ¼ë¡œ ì‚¬ëžŒ ì´ë¯¸ì§€ í¬ë¡­"""
        try:
            # RTMW ì„¤ì •: width=288, height=384
            input_width, input_height = 288, 384
            
            # 1. bboxë¥¼ center, scaleë¡œ ë³€í™˜
            bbox_array = np.array(bbox, dtype=np.float32)
            center, scale = self.bbox_xyxy2cs(bbox_array)
            
            # 2. aspect ratio ê³ ì •
            aspect_ratio = input_width / input_height  # 0.75
            scale = self.fix_aspect_ratio(scale, aspect_ratio)
            
            # 3. ì•„í•€ ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
            warp_mat = self.get_warp_matrix(
                center=center,
                scale=scale,
                rot=0.0,
                output_size=(input_width, input_height)
            )
            
            # 4. ì•„í•€ ë³€í™˜ ì ìš©
            cropped_image = cv2.warpAffine(
                image, 
                warp_mat, 
                (input_width, input_height), 
                flags=cv2.INTER_LINEAR
            )
            
            return cropped_image
                
        except Exception as e:
            print(f"âš ï¸ í¬ë¡­ ì‹¤íŒ¨: {e}")
            return None

    # RTMW ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (streamlined_processor.pyì—ì„œ ê°€ì ¸ì˜´)
    def bbox_xyxy2cs(self, bbox: np.ndarray, padding: float = 1.10) -> Tuple[np.ndarray, np.ndarray]:
        """ë°”ìš´ë”©ë°•ìŠ¤ë¥¼ center, scaleë¡œ ë³€í™˜"""
        dim = bbox.ndim
        if dim == 1:
            bbox = bbox[None, :]
        
        scale = (bbox[..., 2:] - bbox[..., :2]) * padding
        center = (bbox[..., 2:] + bbox[..., :2]) * 0.5
        
        if dim == 1:
            center = center[0]
            scale = scale[0]
        
        return center, scale

    def _rotate_point(self, pt: np.ndarray, angle_rad: float) -> np.ndarray:
        """ì ì„ íšŒì „"""
        cos_val = np.cos(angle_rad)
        sin_val = np.sin(angle_rad)
        return np.array([pt[0] * cos_val - pt[1] * sin_val,
                        pt[0] * sin_val + pt[1] * cos_val])

    def _get_3rd_point(self, a: np.ndarray, b: np.ndarray) -> np.ndarray:
        """ì„¸ ë²ˆì§¸ ì ì„ ê³„ì‚° (ì§êµì )"""
        direction = a - b
        return b + np.array([-direction[1], direction[0]])

    def get_warp_matrix(self, center: np.ndarray, scale: np.ndarray, rot: float, 
                    output_size: Tuple[int, int]) -> np.ndarray:
        """ì•„í•€ ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
        src_w, src_h = scale[:2]
        dst_w, dst_h = output_size[:2]
        
        rot_rad = np.deg2rad(rot)
        src_dir = self._rotate_point(np.array([src_w * -0.5, 0.]), rot_rad)
        dst_dir = np.array([dst_w * -0.5, 0.])
        
        src = np.zeros((3, 2), dtype=np.float32)
        src[0, :] = center
        src[1, :] = center + src_dir
        
        dst = np.zeros((3, 2), dtype=np.float32)
        dst[0, :] = [dst_w * 0.5, dst_h * 0.5]
        dst[1, :] = np.array([dst_w * 0.5, dst_h * 0.5]) + dst_dir
        
        src[2, :] = self._get_3rd_point(src[0, :], src[1, :])
        dst[2, :] = self._get_3rd_point(dst[0, :], dst[1, :])
        
        warp_mat = cv2.getAffineTransform(src, dst)
        return warp_mat

    def fix_aspect_ratio(self, bbox_scale: np.ndarray, aspect_ratio: float) -> np.ndarray:
        """bboxë¥¼ ê³ ì • ì¢…íš¡ë¹„ë¡œ ì¡°ì •"""
        w, h = bbox_scale[0], bbox_scale[1]
        if w > h * aspect_ratio:
            new_h = w / aspect_ratio
            bbox_scale = np.array([w, new_h])
        else:
            new_w = h * aspect_ratio
            bbox_scale = np.array([new_w, h])
        return bbox_scale