import cv2
import numpy as np
from typing import List, Optional, Tuple
from pathlib import Path
from collections import deque

# Add Hailo imports
try:
    from hailo_platform import (HEF, VDevice, HailoStreamInterface, 
                                InferVStreams, ConfigureParams)
    HAILO_AVAILABLE = True
    print("âœ… Hailo platform available")
except ImportError:
    print("âš ï¸ Hailo platform not available, falling back to CPU")
    HAILO_AVAILABLE = False

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    print("âš ï¸ ultralytics ë¯¸ì„¤ì¹˜ - pip install ultralytics")
    YOLO_AVAILABLE = False

class EdgeYOLODetector:
    """ì—£ì§€ ë””ë°”ì´ìŠ¤ìš© YOLO ê²€ì¶œê¸° (Hailo-8 ê°€ì† ì§€ì›)"""
    
    def __init__(self, 
                 yolo_model: str = "yolov8n.pt",
                 hailo_model: str = "yolov8n.hef",  # .hef íŒŒì¼ ê²½ë¡œ
                 use_hailo: bool = True,
                 conf_thresh: float = 0.6,
                 iou_thresh: float = 0.6,
                 max_det: int = 1,
                 img_size: int = 320):
        
        self.conf_thresh = conf_thresh
        self.iou_thresh = iou_thresh
        self.max_det = max_det
        self.img_size = img_size
        self.use_hailo = use_hailo and HAILO_AVAILABLE
        
        if self.use_hailo and hailo_model:
            self._init_hailo(hailo_model)
        else:
            self._init_ultralytics(yolo_model)
    
    def _init_hailo(self, hailo_model: str):
        """Hailo ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            print(f"ðŸ”§ Hailo ëª¨ë¸ ë¡œë”© ì¤‘: {hailo_model}")
            
            # HEF íŒŒì¼ ë¡œë“œ
            self.hef = HEF(hailo_model)
            
            # VDevice ìƒì„±
            self.target = VDevice()
            
            # ë„¤íŠ¸ì›Œí¬ ê·¸ë£¹ ì„¤ì •
            self.network_group = self.target.configure(self.hef)[0]
            self.network_group_params = self.network_group.create_params()
            
            # ìž…ë ¥/ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
            self.input_vstreams_params = self.network_group.make_input_vstream_params(
                quantized=False, format_type=HailoStreamInterface.UINT8
            )
            self.output_vstreams_params = self.network_group.make_output_vstream_params(
                quantized=False, format_type=HailoStreamInterface.FLOAT32
            )
            
            print("âœ… Hailo ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            self.backend = "hailo"
            
        except Exception as e:
            print(f"âŒ Hailo ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
            self._init_ultralytics("yolov8n.pt")
    
    def _init_ultralytics(self, yolo_model: str):
        """Ultralytics ëª¨ë¸ ì´ˆê¸°í™” (CPU/GPU ë°±ì—”ë“œ)"""
        if not YOLO_AVAILABLE:
            raise ImportError("ultralyticsê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install ultralytics")
        
        print(f"ðŸ”§ {yolo_model} ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = YOLO(yolo_model)
        print(f"âœ… {yolo_model} ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        self.backend = "ultralytics"
    
    def detect_persons(self, image: np.ndarray) -> List[List[float]]:
        """ì‚¬ëžŒ ê²€ì¶œ (Hailo ë˜ëŠ” Ultralytics ì‚¬ìš©)"""
        if self.backend == "hailo":
            return self._detect_persons_hailo(image)
        else:
            return self._detect_persons_ultralytics(image)
    
    def _detect_persons_hailo(self, image: np.ndarray) -> List[List[float]]:
        """Hailoë¥¼ ì‚¬ìš©í•œ ì‚¬ëžŒ ê²€ì¶œ"""
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            input_data = self._preprocess_for_hailo(image)
            
            # Hailo ì¶”ë¡ 
            with InferVStreams(self.network_group, 
                             self.input_vstreams_params, 
                             self.output_vstreams_params) as infer_pipeline:
                
                # ì¶”ë¡  ì‹¤í–‰
                outputs = infer_pipeline.infer({
                    list(self.input_vstreams_params.keys())[0]: input_data
                })
                
                # í›„ì²˜ë¦¬
                person_boxes = self._postprocess_hailo_output(outputs, image.shape)
                return person_boxes
                
        except Exception as e:
            print(f"âŒ Hailo ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _detect_persons_ultralytics(self, image: np.ndarray) -> List[List[float]]:
        """ê¸°ì¡´ Ultralytics ê²€ì¶œ ë°©ì‹"""
        try:
            results = self.model(
                image,
                conf=self.conf_thresh,
                iou=self.iou_thresh,
                max_det=1,
                classes=[0],
                verbose=False,
                imgsz=self.img_size
            )
            
            person_boxes = []
            for result in results:
                boxes = result.boxes
                if boxes is not None and len(boxes) > 0:
                    person_coords = boxes.xyxy
                    
                    if hasattr(person_coords, 'cpu'):
                        person_coords = person_coords.cpu().numpy()
                    
                    person_boxes.extend(person_coords.tolist())
            
            return person_boxes
        
        except Exception as e:
            print(f"âŒ YOLO ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _preprocess_for_hailo(self, image: np.ndarray) -> np.ndarray:
        """Hailo ìž…ë ¥ì„ ìœ„í•œ ì „ì²˜ë¦¬"""
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (Hailo ëª¨ë¸ì˜ ìž…ë ¥ í¬ê¸°ì— ë§žì¶¤)
        resized = cv2.resize(image, (self.img_size, self.img_size))
        
        # BGR to RGB ë³€í™˜
        rgb_image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        
        # ì •ê·œí™” (0-255 -> 0-1)
        normalized = rgb_image.astype(np.float32) / 255.0
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ [H,W,C] -> [1,H,W,C]
        input_data = np.expand_dims(normalized, axis=0)
        
        return input_data
    
    def _postprocess_hailo_output(self, outputs: dict, original_shape: tuple) -> List[List[float]]:
        """Hailo ì¶œë ¥ í›„ì²˜ë¦¬"""
        # ì´ ë¶€ë¶„ì€ ì‚¬ìš©í•˜ëŠ” YOLO ëª¨ë¸ì˜ ì¶œë ¥ í˜•ì‹ì— ë”°ë¼ ìˆ˜ì • í•„ìš”
        # ì¼ë°˜ì ìœ¼ë¡œ [batch, boxes, 5+classes] í˜•íƒœ
        
        person_boxes = []
        
        # ì¶œë ¥ì—ì„œ ì²« ë²ˆì§¸ í…ì„œ ê°€ì ¸ì˜¤ê¸° (ë³´í†µ detection ê²°ê³¼)
        detection_output = list(outputs.values())[0]
        
        # í›„ì²˜ë¦¬ ë¡œì§ (NMS, ì¢Œí‘œ ë³€í™˜ ë“±)
        # ì´ ë¶€ë¶„ì€ ì‹¤ì œ Hailo ëª¨ë¸ì˜ ì¶œë ¥ í˜•ì‹ì— ë§žê²Œ êµ¬í˜„í•´ì•¼ í•¨
        
        return person_boxes
    
    def crop_person_image_rtmw(self, image: np.ndarray, bbox: List[float]) -> Optional[np.ndarray]:
        """RTMW ë°©ì‹ìœ¼ë¡œ ì‚¬ëžŒ ì´ë¯¸ì§€ í¬ë¡­"""
        try:
            # RTMW ì„¤ì •: width=288, height=384
            input_width, input_height = 288, 384
            
            # 1. bboxë¥¼ center, scaleë¡œ ë³€í™˜
            bbox_array = np.array(bbox, dtype=np.float32)
            center, scale = self.bbox_xyxy2cs(bbox_array)
            
            # 2. aspect ratio ê³ ì •
            aspect_ratio = input_width / input_height  # 0.75
            scale = self.fix_aspect_ratio(scale, aspect_ratio)
            
            # 3. ì•„í•€ ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
            warp_mat = self.get_warp_matrix(
                center=center,
                scale=scale,
                rot=0.0,
                output_size=(input_width, input_height)
            )
            
            # 4. ì•„í•€ ë³€í™˜ ì ìš©
            cropped_image = cv2.warpAffine(
                image, 
                warp_mat, 
                (input_width, input_height), 
                flags=cv2.INTER_LINEAR
            )
            
            return cropped_image
                
        except Exception as e:
            print(f"âš ï¸ í¬ë¡­ ì‹¤íŒ¨: {e}")
            return None

    # RTMW ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (streamlined_processor.pyì—ì„œ ê°€ì ¸ì˜´)
    def bbox_xyxy2cs(self, bbox: np.ndarray, padding: float = 1.10) -> Tuple[np.ndarray, np.ndarray]:
        """ë°”ìš´ë”©ë°•ìŠ¤ë¥¼ center, scaleë¡œ ë³€í™˜"""
        dim = bbox.ndim
        if dim == 1:
            bbox = bbox[None, :]
        
        scale = (bbox[..., 2:] - bbox[..., :2]) * padding
        center = (bbox[..., 2:] + bbox[..., :2]) * 0.5
        
        if dim == 1:
            center = center[0]
            scale = scale[0]
        
        return center, scale

    def _rotate_point(self, pt: np.ndarray, angle_rad: float) -> np.ndarray:
        """ì ì„ íšŒì „"""
        cos_val = np.cos(angle_rad)
        sin_val = np.sin(angle_rad)
        return np.array([pt[0] * cos_val - pt[1] * sin_val,
                        pt[0] * sin_val + pt[1] * cos_val])

    def _get_3rd_point(self, a: np.ndarray, b: np.ndarray) -> np.ndarray:
        """ì„¸ ë²ˆì§¸ ì ì„ ê³„ì‚° (ì§êµì )"""
        direction = a - b
        return b + np.array([-direction[1], direction[0]])

    def get_warp_matrix(self, center: np.ndarray, scale: np.ndarray, rot: float, 
                    output_size: Tuple[int, int]) -> np.ndarray:
        """ì•„í•€ ë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
        src_w, src_h = scale[:2]
        dst_w, dst_h = output_size[:2]
        
        rot_rad = np.deg2rad(rot)
        src_dir = self._rotate_point(np.array([src_w * -0.5, 0.]), rot_rad)
        dst_dir = np.array([dst_w * -0.5, 0.])
        
        src = np.zeros((3, 2), dtype=np.float32)
        src[0, :] = center
        src[1, :] = center + src_dir
        
        dst = np.zeros((3, 2), dtype=np.float32)
        dst[0, :] = [dst_w * 0.5, dst_h * 0.5]
        dst[1, :] = np.array([dst_w * 0.5, dst_h * 0.5]) + dst_dir
        
        src[2, :] = self._get_3rd_point(src[0, :], src[1, :])
        dst[2, :] = self._get_3rd_point(dst[0, :], dst[1, :])
        
        warp_mat = cv2.getAffineTransform(src, dst)
        return warp_mat

    def fix_aspect_ratio(self, bbox_scale: np.ndarray, aspect_ratio: float) -> np.ndarray:
        """bboxë¥¼ ê³ ì • ì¢…íš¡ë¹„ë¡œ ì¡°ì •"""
        w, h = bbox_scale[0], bbox_scale[1]
        if w > h * aspect_ratio:
            new_h = w / aspect_ratio
            bbox_scale = np.array([w, new_h])
        else:
            new_w = h * aspect_ratio
            bbox_scale = np.array([new_w, h])
        return bbox_scale