import cv2
import numpy as np
import mediapipe as mp
import os
from typing import Optional, Tuple
from collections import deque

try:
    from openvino.runtime import Core
    OPENVINO_AVAILABLE = True
except ImportError:
    print("âš ï¸ OpenVINOê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install openvino ì‹¤í–‰í•˜ì„¸ìš”.")
    OPENVINO_AVAILABLE = False

class SignLanguageDetector:
    """OpenVINO ê¸°ë°˜ ASL ìˆ˜í™” ì¸ì‹ ëª¨ë¸"""
    
    def __init__(self, model_path: str = None):
        print("ğŸ”„ OpenVINO ASL ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        # MediaPipe ì´ˆê¸°í™”
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=True,
            max_num_hands=2,
            min_detection_confidence=0.6,
            min_tracking_confidence=0.5
        )
        
        # ì‹œê°í™”ìš©
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ë²„í¼ (16í”„ë ˆì„)
        self.frame_sequence = deque(maxlen=16)
        
        # OpenVINO ëª¨ë¸ ë¡œë“œ
        self.model, self.input_layer, self.output_layer = self._load_openvino_model(model_path)
        
        # ASL ë¼ë²¨
        self.labels = [
            'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 
            'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
            'del', 'nothing', 'space'
        ]
        
        print("âœ… OpenVINO ASL ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_openvino_model(self, model_path: str = None):
        """OpenVINO ëª¨ë¸ ë¡œë“œ"""
        try:
            if not OPENVINO_AVAILABLE:
                print("âš ï¸ OpenVINO ì—†ìŒ, ë£° ê¸°ë°˜ ì¸ì‹ ì‚¬ìš©")
                return None, None, None
            
            # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            if model_path is None:
                model_xml = "models/asl_model.xml"
                model_bin = "models/asl_model.bin"
            else:
                model_xml = model_path
                model_bin = model_path.replace('.xml', '.bin')
            
            if not os.path.exists(model_xml) or not os.path.exists(model_bin):
                print(f"âš ï¸ OpenVINO ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_xml}")
                return None, None, None
            
            # OpenVINO Core ì´ˆê¸°í™”
            ie = Core()
            
            # ëª¨ë¸ ë¡œë“œ
            model = ie.read_model(model=model_xml, weights=model_bin)
            compiled_model = ie.compile_model(model=model, device_name="CPU")
            
            # ì…ë ¥/ì¶œë ¥ ë ˆì´ì–´ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            input_layer = compiled_model.input(0)
            output_layer = compiled_model.output(0)
            
            print(f"âœ… OpenVINO ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_xml}")
            print(f"ğŸ“ ì…ë ¥ í˜•íƒœ: {input_layer.shape}")
            print(f"ğŸ“ ì¶œë ¥ í˜•íƒœ: {output_layer.shape}")
            
            return compiled_model, input_layer, output_layer
            
        except Exception as e:
            print(f"âš ï¸ OpenVINO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None, None, None
    
    def _preprocess_image_sequence(self, image: np.ndarray) -> np.ndarray:
        """ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        try:
            if self.input_layer:
                input_shape = self.input_layer.shape
                print(f"ğŸ” ëª¨ë¸ ì…ë ¥ í˜•íƒœ: {input_shape}")
                
                # [N, C, T, H, W] í˜•íƒœ (ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤)
                if len(input_shape) == 5:
                    n, c, t, h, w = input_shape
                    
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    processed = cv2.resize(image, (w, h))
                    processed = processed.astype(np.float32) / 255.0
                    processed = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)
                    processed = np.transpose(processed, (2, 0, 1))  # [C, H, W]
                    
                    # ì‹œí€€ìŠ¤ ë²„í¼ì— ì¶”ê°€
                    self.frame_sequence.append(processed)
                    
                    # 16í”„ë ˆì„ì´ ëª¨ì´ë©´ ì‹œí€€ìŠ¤ ìƒì„±
                    if len(self.frame_sequence) == t:
                        sequence = np.stack(list(self.frame_sequence), axis=1)  # [C, T, H, W]
                        sequence = np.expand_dims(sequence, axis=0)  # [N, C, T, H, W]
                        return sequence
                    else:
                        # í”„ë ˆì„ì´ ë¶€ì¡±í•˜ë©´ í˜„ì¬ í”„ë ˆì„ì„ ë°˜ë³µí•´ì„œ 16ê°œ ì±„ì›€
                        while len(self.frame_sequence) < t:
                            self.frame_sequence.append(processed)
                        sequence = np.stack(list(self.frame_sequence), axis=1)
                        sequence = np.expand_dims(sequence, axis=0)
                        return sequence
                        
                # [N, C, H, W] í˜•íƒœ (ë‹¨ì¼ ì´ë¯¸ì§€) - ë°±ì—…
                elif len(input_shape) == 4:
                    processed = cv2.resize(image, (input_shape[3], input_shape[2]))
                    processed = processed.astype(np.float32) / 255.0
                    processed = cv2.cvtColor(processed, cv2.COLOR_BGR2RGB)
                    processed = np.transpose(processed, (2, 0, 1))
                    processed = np.expand_dims(processed, axis=0)
                    return processed
            
            # ê¸°ë³¸ ì „ì²˜ë¦¬
            processed = cv2.resize(image, (224, 224))
            processed = processed.astype(np.float32) / 255.0
            processed = np.expand_dims(processed, axis=0)
            return processed
            
        except Exception as e:
            print(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def _predict_with_openvino(self, image: np.ndarray) -> str:
        """OpenVINO ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
        try:
            if not self.model:
                return "NO_MODEL"
            
            # ë¹„ë””ì˜¤ ì‹œí€€ìŠ¤ ì „ì²˜ë¦¬
            input_data = self._preprocess_image_sequence(image)
            
            if input_data is None:
                return "PREPROCESS_ERROR"
            
            print(f"ğŸ” ì…ë ¥ ë°ì´í„° í˜•íƒœ: {input_data.shape}")
            
            # ëª¨ë¸ ì¶”ë¡ 
            result = self.model([input_data])[self.output_layer]
            
            # ê²°ê³¼ ì²˜ë¦¬
            predictions = result[0]  # ì²« ë²ˆì§¸ ë°°ì¹˜
            predicted_class = np.argmax(predictions)
            confidence = np.max(predictions)
            
            print(f"ğŸ” OpenVINO ì˜ˆì¸¡: í´ë˜ìŠ¤={predicted_class}, ì‹ ë¢°ë„={confidence:.3f}")
            
            if confidence > 0.3:
                return self.labels[predicted_class % len(self.labels)]
            else:
                return "UNCERTAIN"
                
        except Exception as e:
            print(f"OpenVINO ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return "PREDICTION_ERROR"
    
    def _predict_with_mediapipe_rules(self, image: np.ndarray) -> str:
        """MediaPipe ë£° ê¸°ë°˜ ë°±ì—… ì˜ˆì¸¡"""
        try:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_image)
            
            if results.multi_hand_landmarks:
                landmarks = results.multi_hand_landmarks[0].landmark
                
                # ê°„ë‹¨í•œ ì œìŠ¤ì²˜ ë¶„ë¥˜
                thumb_tip = landmarks[4]
                index_tip = landmarks[8]
                middle_tip = landmarks[12]
                ring_tip = landmarks[16]
                pinky_tip = landmarks[20]
                
                # ì†ê°€ë½ í´ì§„ ìƒíƒœ í™•ì¸
                fingers_up = []
                
                # ì—„ì§€ (xì¶• ê¸°ì¤€)
                if thumb_tip.x > landmarks[3].x:
                    fingers_up.append(1)
                else:
                    fingers_up.append(0)
                
                # ë‚˜ë¨¸ì§€ ì†ê°€ë½ë“¤ (yì¶• ê¸°ì¤€)
                finger_tips = [index_tip, middle_tip, ring_tip, pinky_tip]
                finger_pips = [landmarks[6], landmarks[10], landmarks[14], landmarks[18]]
                
                for tip, pip in zip(finger_tips, finger_pips):
                    if tip.y < pip.y:
                        fingers_up.append(1)
                    else:
                        fingers_up.append(0)
                
                # ì œìŠ¤ì²˜ ë¶„ë¥˜
                fingers_count = sum(fingers_up)
                
                if fingers_count == 0:
                    return "A"  # ì£¼ë¨¹
                elif fingers_count == 1 and fingers_up[1] == 1:
                    return "D"  # ê²€ì§€ë§Œ
                elif fingers_count == 2 and fingers_up[1] == 1 and fingers_up[2] == 1:
                    return "V"  # ë¸Œì´ì‚¬ì¸
                elif fingers_count == 5:
                    return "B"  # í¼ì¹œ ì†
                else:
                    return f"GESTURE_{fingers_count}"
            else:
                return "NO_HANDS"
                
        except Exception as e:
            print(f"ë£° ê¸°ë°˜ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return "RULE_ERROR"
    
    def predict_sign_with_visualization(self, image: np.ndarray) -> Tuple[str, np.ndarray]:
        """ìˆ˜í™” ì˜ˆì¸¡ + ì‹œê°í™”"""
        try:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            hands_results = self.hands.process(rgb_image)
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬ (ì‹œê°í™”ìš©)
            annotated_image = image.copy()
            
            sign_result = "NO_HANDS"
            
            if hands_results.multi_hand_landmarks:
                # ì† ë¼ˆëŒ€ ê·¸ë¦¬ê¸°
                for hand_landmarks in hands_results.multi_hand_landmarks:
                    self.mp_drawing.draw_landmarks(
                        annotated_image,
                        hand_landmarks,
                        self.mp_hands.HAND_CONNECTIONS,
                        self.mp_drawing_styles.get_default_hand_landmarks_style(),
                        self.mp_drawing_styles.get_default_hand_connections_style()
                    )
                
                # OpenVINO ëª¨ë¸ë¡œ ì˜ˆì¸¡ (ìš°ì„ ) - ì‹¤ì‹œê°„ì—ì„œëŠ” ë£° ê¸°ë°˜ ì‚¬ìš©
                # if self.model:
                #     sign_result = self._predict_with_openvino(image)
                #     method = "OpenVINO"
                # else:
                # ì‹¤ì‹œê°„ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë£° ê¸°ë°˜ ì‚¬ìš© (ë” ë¹ ë¦„)
                sign_result = self._predict_with_mediapipe_rules(image)
                method = "Rules"
                
                # ê²°ê³¼ í…ìŠ¤íŠ¸ í‘œì‹œ
                cv2.putText(
                    annotated_image, 
                    f"ASL ({method}): {sign_result}", 
                    (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    0.7, (0, 255, 0), 2
                )
            
            return sign_result, annotated_image
            
        except Exception as e:
            print(f"ì‹œê°í™” ìˆ˜í™” ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return "ERROR", image
    
    def predict_sign(self, image: np.ndarray) -> str:
        """ê°„ë‹¨í•œ ìˆ˜í™” ì˜ˆì¸¡ (ì‹œê°í™” ì—†ìŒ)"""
        result, _ = self.predict_sign_with_visualization(image)
        return result