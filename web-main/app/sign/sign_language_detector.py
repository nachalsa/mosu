
import cv2
import numpy as np
import mediapipe as mp
from typing import Optional, Tuple

class SignLanguageDetector:
    def _predict_with_mediapipe_rules(self, image: np.ndarray) -> str:
        """MediaPipe ì† ëœë“œë§ˆí¬ ê¸°ë°˜ ê°„ë‹¨í•œ rule-based ìˆ˜í™” ì¸ì‹ (ì˜ˆì‹œ: ì—„ì§€, ê²€ì§€ ë“± í´ì§„ ì†ê°€ë½ ê°œìˆ˜)"""
        try:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.hands.process(rgb_image)
            if not results.multi_hand_landmarks:
                return "NO_HANDS"
            # ì˜ˆì‹œ: í•œ ì†ë§Œ ì¸ì‹, í´ì§„ ì†ê°€ë½ ê°œìˆ˜ë¡œ ë‹¨ìˆœ ë¶„ë¥˜
            hand_landmarks = results.multi_hand_landmarks[0]
            landmarks = hand_landmarks.landmark
            # ì†ê°€ë½ tip ì¸ë±ìŠ¤: [4, 8, 12, 16, 20] (ì—„ì§€~ìƒˆë¼)
            tips = [4, 8, 12, 16, 20]
            fingers_up = []
            # ì—„ì§€: xì¶•, ë‚˜ë¨¸ì§€: yì¶•
            if landmarks[tips[0]].x < landmarks[tips[0] - 1].x:
                fingers_up.append(1)
            else:
                fingers_up.append(0)
            for tip in tips[1:]:
                if landmarks[tip].y < landmarks[tip - 2].y:
                    fingers_up.append(1)
                else:
                    fingers_up.append(0)
            up_count = sum(fingers_up)
            # ê°„ë‹¨í•œ rule: ì†ê°€ë½ ê°œìˆ˜ë¡œ ë¶„ë¥˜
            if up_count == 0:
                return "FIST"
            elif up_count == 1:
                return "ONE"
            elif up_count == 2:
                return "TWO"
            elif up_count == 3:
                return "THREE"
            elif up_count == 4:
                return "FOUR"
            elif up_count == 5:
                return "FIVE"
            else:
                return f"{up_count}_FINGERS"
        except Exception as e:
            print(f"MediaPipe rule ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return "ERROR"
    """MediaPipe ë£° ê¸°ë°˜ ASL ìˆ˜í™” ì¸ì‹ê¸°"""
    
    def __init__(self, model_path: str = None):
        print("ğŸ”„ MediaPipe ë£° ê¸°ë°˜ ìˆ˜í™” ì¸ì‹ê¸° ì´ˆê¸°í™” ì¤‘...")
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=True,
            max_num_hands=2,
            min_detection_confidence=0.6,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        print("âœ… MediaPipe ë£° ê¸°ë°˜ ìˆ˜í™” ì¸ì‹ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    # OpenVINO ê´€ë ¨ ë©”ì„œë“œ ì™„ì „ ì œê±°
    
    # _preprocess_image_sequence ë“± OpenVINO ê´€ë ¨ ë©”ì„œë“œ ì™„ì „ ì œê±°
    def predict_sign_with_visualization(self, image: np.ndarray) -> Tuple[str, np.ndarray]:
        """MediaPipe ë£° ê¸°ë°˜ ìˆ˜í™” ì˜ˆì¸¡ + ì‹œê°í™”"""
        try:
            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            hands_results = self.hands.process(rgb_image)
            annotated_image = image.copy()
            sign_result = "NO_HANDS"
            method = "Rules"
            if hands_results.multi_hand_landmarks:
                for hand_landmarks in hands_results.multi_hand_landmarks:
                    self.mp_drawing.draw_landmarks(
                        annotated_image,
                        hand_landmarks,
                        self.mp_hands.HAND_CONNECTIONS,
                        self.mp_drawing_styles.get_default_hand_landmarks_style(),
                        self.mp_drawing_styles.get_default_hand_connections_style()
                    )
                sign_result = self._predict_with_mediapipe_rules(image)
                method = "Rules"
                cv2.putText(
                    annotated_image, 
                    f"ASL ({method}): {sign_result}", 
                    (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    0.7, (0, 255, 0), 2
                )
            return sign_result, annotated_image
        except Exception as e:
            print(f"ì‹œê°í™” ìˆ˜í™” ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return "ERROR", image
    
    def predict_sign(self, image: np.ndarray) -> str:
        """MediaPipe ë£° ê¸°ë°˜ ìˆ˜í™” ì˜ˆì¸¡ (ì‹œê°í™” ì—†ìŒ)"""
        return self._predict_with_mediapipe_rules(image)