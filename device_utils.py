"""
ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ ë° ì„¤ì • ìœ í‹¸ë¦¬í‹°
"""
import torch
import logging

logger = logging.getLogger(__name__)

class DeviceManager:
    """í†µí•© ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì"""
    
    @staticmethod
    def detect_best_device(preferred_device: str = "auto") -> torch.device:
        """ìµœì ì˜ ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€"""
        
        if preferred_device != "auto":
            # ì‚¬ìš©ì ì§€ì • ë””ë°”ì´ìŠ¤ ê²€ì¦
            return DeviceManager._validate_device(preferred_device)
        
        # ìë™ ê°ì§€ ìˆœì„œ: XPU > CUDA > CPU
        logger.info("ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        
        # 1. XPU í™•ì¸ (Intel GPU)
        xpu_device = DeviceManager._check_xpu()
        if xpu_device:
            return xpu_device
        
        # 2. CUDA í™•ì¸ (NVIDIA GPU)
        cuda_device = DeviceManager._check_cuda()
        if cuda_device:
            return cuda_device
        
        # 3. CPU í´ë°±
        logger.info("ğŸ’» CPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
        return torch.device("cpu")
    
    @staticmethod
    def _check_xpu() -> torch.device:
        """XPU ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        try:
            # XPU ëª¨ë“ˆ ì¡´ì¬ í™•ì¸
            if not hasattr(torch, 'xpu'):
                logger.debug("XPU ëª¨ë“ˆ ë¯¸ì§€ì›")
                return None
            
            # device_count() ë°©ì‹ìœ¼ë¡œ í™•ì¸
            try:
                device_count = torch.xpu.device_count()
                if device_count > 0:
                    logger.info(f"âš¡ XPU ë””ë°”ì´ìŠ¤ ê°ì§€: {device_count}ê°œ ë””ë°”ì´ìŠ¤")
                    # ì¶”ê°€ ê²€ì¦: ì‹¤ì œ í…ì„œ ìƒì„± í…ŒìŠ¤íŠ¸
                    test_tensor = torch.tensor([1.0], device='xpu:0')
                    logger.info(f"âœ… XPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {test_tensor.device}")
                    return torch.device("xpu:0")
            except Exception as e:
                logger.debug(f"XPU device_count() ì‹¤íŒ¨: {e}")
            
            # is_available() ë°©ì‹ìœ¼ë¡œ í™•ì¸ (ìˆëŠ” ê²½ìš°)
            try:
                if hasattr(torch.xpu, 'is_available') and torch.xpu.is_available():
                    test_tensor = torch.tensor([1.0], device='xpu')
                    logger.info(f"âš¡ XPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {test_tensor.device}")
                    return torch.device("xpu")
            except Exception as e:
                logger.debug(f"XPU is_available() ì‹¤íŒ¨: {e}")
            
            # ì§ì ‘ í…ŒìŠ¤íŠ¸ ë°©ì‹
            try:
                test_tensor = torch.tensor([1.0], device='xpu')
                logger.info(f"âš¡ XPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {test_tensor.device}")
                return torch.device("xpu")
            except Exception as e:
                logger.debug(f"XPU ì§ì ‘ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            logger.debug(f"XPU ì „ì²´ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return None
    
    @staticmethod
    def _check_cuda() -> torch.device:
        """CUDA ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        try:
            if torch.cuda.is_available():
                device_count = torch.cuda.device_count()
                current_device = torch.cuda.current_device()
                device_name = torch.cuda.get_device_name(current_device)
                
                logger.info(f"ğŸ”¥ CUDA ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {device_name} ({device_count}ê°œ ë””ë°”ì´ìŠ¤)")
                return torch.device(f"cuda:{current_device}")
        except Exception as e:
            logger.debug(f"CUDA í™•ì¸ ì‹¤íŒ¨: {e}")
        
        return None
    
    @staticmethod
    def _validate_device(device_str: str) -> torch.device:
        """ì‚¬ìš©ì ì§€ì • ë””ë°”ì´ìŠ¤ ê²€ì¦"""
        try:
            device = torch.device(device_str)
            
            if device.type == "cuda":
                if not torch.cuda.is_available():
                    logger.warning("âš ï¸ CUDA ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ ì‚¬ìš© ë¶ˆê°€ - CPUë¡œ í´ë°±")
                    return torch.device("cpu")
                logger.info(f"ğŸ”¥ ì§€ì •ëœ CUDA ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {device}")
                return device
            
            elif device.type == "xpu":
                xpu_device = DeviceManager._check_xpu()
                if xpu_device is None:
                    logger.warning("âš ï¸ XPU ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ ì‚¬ìš© ë¶ˆê°€ - CPUë¡œ í´ë°±")
                    return torch.device("cpu")
                logger.info(f"âš¡ ì§€ì •ëœ XPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {device}")
                return device
            
            elif device.type == "cpu":
                logger.info("ğŸ’» ì§€ì •ëœ CPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
                return device
            
            else:
                logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë””ë°”ì´ìŠ¤ íƒ€ì…: {device} - CPUë¡œ í´ë°±")
                return torch.device("cpu")
                
        except Exception as e:
            logger.error(f"âŒ ë””ë°”ì´ìŠ¤ ê²€ì¦ ì‹¤íŒ¨: {e} - CPUë¡œ í´ë°±")
            return torch.device("cpu")
    
    @staticmethod
    def get_device_info(device: torch.device) -> dict:
        """ë””ë°”ì´ìŠ¤ ì •ë³´ ë°˜í™˜"""
        info = {
            'type': device.type,
            'index': device.index,
            'name': str(device)
        }
        
        try:
            if device.type == "cuda":
                info.update({
                    'name': torch.cuda.get_device_name(device),
                    'memory_total': torch.cuda.get_device_properties(device).total_memory,
                    'memory_cached': torch.cuda.memory_cached(device),
                    'memory_allocated': torch.cuda.memory_allocated(device)
                })
            elif device.type == "xpu":
                # XPU ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
                try:
                    if hasattr(torch.xpu, 'get_device_name'):
                        info['name'] = torch.xpu.get_device_name(device.index)
                except:
                    pass
            elif device.type == "cpu":
                import os
                info.update({
                    'cores': os.cpu_count(),
                    'threads': torch.get_num_threads()
                })
        except Exception as e:
            logger.debug(f"ë””ë°”ì´ìŠ¤ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return info
    
    @staticmethod
    def optimize_for_device(device: torch.device):
        """ë””ë°”ì´ìŠ¤ë³„ ìµœì í™” ì„¤ì •"""
        if device.type == "cuda":
            # CUDA ìµœì í™”
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.enabled = True
            logger.info("ğŸ”¥ CUDA ìµœì í™” ì„¤ì • ì™„ë£Œ")
            
        elif device.type == "xpu":
            # XPU ìµœì í™” (ê°€ëŠ¥í•œ ê²½ìš°)
            try:
                # XPU ê´€ë ¨ ìµœì í™” ì„¤ì •
                logger.info("âš¡ XPU ìµœì í™” ì„¤ì • ì™„ë£Œ")
            except:
                pass
                
        elif device.type == "cpu":
            # CPU ìµœì í™”
            torch.set_num_threads(min(8, torch.get_num_threads()))
            logger.info("ğŸ’» CPU ìµœì í™” ì„¤ì • ì™„ë£Œ")

def get_device_string(device: torch.device) -> str:
    """ë””ë°”ì´ìŠ¤ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if device.index is not None:
        return f"{device.type}:{device.index}"
    return device.type

# í¸ì˜ í•¨ìˆ˜ë“¤
def auto_device(preferred: str = "auto") -> torch.device:
    """ìë™ ë””ë°”ì´ìŠ¤ ì„ íƒ"""
    return DeviceManager.detect_best_device(preferred)

def device_info(device: torch.device = None) -> dict:
    """ë””ë°”ì´ìŠ¤ ì •ë³´"""
    if device is None:
        device = auto_device()
    return DeviceManager.get_device_info(device)

def optimize_device(device: torch.device = None):
    """ë””ë°”ì´ìŠ¤ ìµœì í™”"""
    if device is None:
        device = auto_device()
    DeviceManager.optimize_for_device(device)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    logging.basicConfig(level=logging.INFO)
    
    print("=== ë””ë°”ì´ìŠ¤ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸ ===")
    
    # ìë™ ê°ì§€
    device = auto_device()
    print(f"ê°ì§€ëœ ë””ë°”ì´ìŠ¤: {device}")
    
    # ì •ë³´ ì¶œë ¥
    info = device_info(device)
    print(f"ë””ë°”ì´ìŠ¤ ì •ë³´: {info}")
    
    # ìµœì í™” ì ìš©
    optimize_device(device)
    
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
