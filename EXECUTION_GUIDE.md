# ğŸš€ ìˆ˜í™” ì¸ì‹ AI ëª¨ë¸ - ì‹¤í–‰ ê°€ì´ë“œ

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
mosu/
â”œâ”€â”€ ğŸ“Š ë°ì´í„° ì²˜ë¦¬
â”‚   â”œâ”€â”€ mosuModel/data/
â”‚   â”‚   â”œâ”€â”€ sign_language_dataset_lzf.h5      # ìˆ˜í™” ë©”íƒ€ë°ì´í„° (LZF ì••ì¶•)
â”‚   â”‚   â”œâ”€â”€ poses/batch_03_*_F_poses.h5       # í¬ì¦ˆ/í”„ë ˆì„ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ unified_dataloader.py             # í†µí•© ë°ì´í„° ë¡œë”
â”‚   â”‚   â”œâ”€â”€ pytorch_dataloader.py             # ê¸°ë³¸ PyTorch ë¡œë”
â”‚   â”‚   â””â”€â”€ complete_data_pipeline.py         # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”‚   â”‚
â”œâ”€â”€ ğŸ§  AI ëª¨ë¸
â”‚   â”œâ”€â”€ mosuModel/
â”‚   â”‚   â”œâ”€â”€ sign_language_models.py           # ëª¨ë¸ ì•„í‚¤í…ì²˜ë“¤
â”‚   â”‚   â”œâ”€â”€ train_sign_language.py            # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ evaluate_sign_language.py         # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â””â”€â”€ sign_translation_server.py        # ì‹¤ì‹œê°„ ë²ˆì—­ ì„œë²„
â”‚   â”‚
â”œâ”€â”€ ğŸ¥ ì‹¤ì‹œê°„ ì²˜ë¦¬
â”‚   â”œâ”€â”€ pose-server.py                        # í¬ì¦ˆ ì¶”ì • ì„œë²„
â”‚   â”œâ”€â”€ yolo-server.py                        # ì‚¬ëŒ ê²€ì¶œ ì„œë²„
â”‚   â””â”€â”€ cmd-pose, cmd-yolo                    # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ë“¤
â”‚   â”‚
â””â”€â”€ ğŸ“š ë¬¸ì„œ
    â”œâ”€â”€ docs/SIGN_LANGUAGE_MODEL_PLAN.md      # ì „ì²´ ê³„íšì„œ
    â””â”€â”€ docs/PROJECT_PLAN.md                  # í”„ë¡œì íŠ¸ ê³„íš
```

## ğŸ¯ ë‹¨ê³„ë³„ ì‹¤í–‰ ê°€ì´ë“œ

### Phase 1: í™˜ê²½ ì„¤ì •

```bash
# 1. Python í™˜ê²½ ì„¤ì •
cd /home/jy/gitwork/mosu
python -m venv .venv
source .venv/bin/activate

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
pip install torch torchvision torchaudio
pip install h5py numpy pandas opencv-python
pip install flask requests tqdm
pip install matplotlib seaborn scikit-learn
pip install tensorboard
pip install mmpose ultralytics  # í¬ì¦ˆ ì¶”ì •ìš©

# 3. ë°ì´í„° í™•ì¸
python mosuModel/data/unified_dataloader.py
```

### Phase 2: ë°ì´í„° ê²€ì¦ ë° í†µí•©

```bash
# 1. ë°ì´í„° êµ¬ì¡° í™•ì¸
cd mosuModel/data
python -c "
from unified_dataloader import create_unified_dataloader
loader, dataset = create_unified_dataloader(
    'sign_language_dataset_lzf.h5',
    'poses/',
    batch_size=4,
    validate_matching=True
)
print('Dataset size:', len(dataset))
print('Stats:', dataset.get_stats())
"

# 2. ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
python unified_dataloader.py
```

### Phase 3: ëª¨ë¸ í•™ìŠµ

```bash
# 1. Baseline CNN-LSTM ëª¨ë¸ í•™ìŠµ
python mosuModel/train_sign_language.py \
  --sign-lang-path mosuModel/data/sign_language_dataset_lzf.h5 \
  --pose-data-dir mosuModel/data/poses/ \
  --model-type baseline \
  --batch-size 8 \
  --num-epochs 30 \
  --learning-rate 1e-3 \
  --max-frames 100 \
  --save-dir checkpoints/baseline \
  --log-dir logs/baseline

# 2. Transformer ëª¨ë¸ í•™ìŠµ
python mosuModel/train_sign_language.py \
  --sign-lang-path mosuModel/data/sign_language_dataset_lzf.h5 \
  --pose-data-dir mosuModel/data/poses/ \
  --model-type transformer \
  --batch-size 6 \
  --num-epochs 50 \
  --learning-rate 5e-4 \
  --max-frames 100 \
  --save-dir checkpoints/transformer \
  --log-dir logs/transformer

# 3. Multi-modal ëª¨ë¸ í•™ìŠµ
python mosuModel/train_sign_language.py \
  --sign-lang-path mosuModel/data/sign_language_dataset_lzf.h5 \
  --pose-data-dir mosuModel/data/poses/ \
  --model-type multimodal \
  --batch-size 4 \
  --num-epochs 40 \
  --learning-rate 3e-4 \
  --max-frames 100 \
  --save-dir checkpoints/multimodal \
  --log-dir logs/multimodal
```

### Phase 4: ëª¨ë¸ í‰ê°€

```bash
# 1. í•™ìŠµëœ ëª¨ë¸ í‰ê°€
python mosuModel/evaluate_sign_language.py \
  --checkpoint checkpoints/baseline/best_model.pth \
  --sign-lang-path mosuModel/data/sign_language_dataset_lzf.h5 \
  --pose-data-dir mosuModel/data/poses/ \
  --model-type baseline \
  --batch-size 16 \
  --results-dir evaluation_results/baseline

# 2. Transformer ëª¨ë¸ í‰ê°€  
python mosuModel/evaluate_sign_language.py \
  --checkpoint checkpoints/transformer/best_model.pth \
  --sign-lang-path mosuModel/data/sign_language_dataset_lzf.h5 \
  --pose-data-dir mosuModel/data/poses/ \
  --model-type transformer \
  --batch-size 16 \
  --results-dir evaluation_results/transformer

# 3. ê²°ê³¼ í™•ì¸
cat evaluation_results/baseline/metrics.json
```

### Phase 5: ì‹¤ì‹œê°„ ë²ˆì—­ ì„œë²„ ì‹¤í–‰

```bash
# 1. Vocabulary JSON ìƒì„±
python -c "
from mosuModel.data.unified_dataloader import create_unified_dataloader
_, dataset = create_unified_dataloader('mosuModel/data/sign_language_dataset_lzf.h5', 'mosuModel/data/poses/')
import json
with open('vocabulary.json', 'w', encoding='utf-8') as f:
    json.dump(dataset.get_vocabulary(), f, ensure_ascii=False, indent=2)
print('Vocabulary saved to vocabulary.json')
"

# 2. ì‹¤ì‹œê°„ ë²ˆì—­ ì„œë²„ ì‹¤í–‰
python mosuModel/sign_translation_server.py \
  --checkpoint checkpoints/baseline/best_model.pth \
  --model-type baseline \
  --vocabulary vocabulary.json \
  --host 0.0.0.0 \
  --port 5001 \
  --max-frames 100 \
  --min-frames 30 \
  --confidence-threshold 0.1
```

### Phase 6: ì „ì²´ ì‹œìŠ¤í…œ í†µí•©

```bash
# Terminal 1: í¬ì¦ˆ ì¶”ì • ì„œë²„
python pose-server.py \
  --config configs/rtmw-l_8xb320-270e_cocktail14-384x288.py \
  --checkpoint models/rtmw-dw-x-l_simcc-cocktail14_270e-384x288-f840f204_20231122.pth \
  --port 5000

# Terminal 2: ìˆ˜í™” ë²ˆì—­ ì„œë²„  
python mosuModel/sign_translation_server.py \
  --checkpoint checkpoints/baseline/best_model.pth \
  --model-type baseline \
  --vocabulary vocabulary.json \
  --port 5001

# Terminal 3: ì—£ì§€ í´ë¼ì´ì–¸íŠ¸ (YOLO + í†µí•©)
python yolo-server.py \
  --pose-server http://localhost:5000 \
  --translation-server http://localhost:5001 \
  --camera 0
```

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### TensorBoard ë¡œê·¸ í™•ì¸
```bash
# í•™ìŠµ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
tensorboard --logdir logs --port 6006
# http://localhost:6006 ì—ì„œ í™•ì¸
```

### API í…ŒìŠ¤íŠ¸
```bash
# 1. í—¬ìŠ¤ ì²´í¬
curl http://localhost:5001/health

# 2. í†µê³„ í™•ì¸
curl http://localhost:5001/stats

# 3. Vocabulary í™•ì¸
curl http://localhost:5001/vocabulary

# 4. ì´ë¯¸ì§€ ë²ˆì—­ í…ŒìŠ¤íŠ¸
curl -X POST -F "image=@test_frame.jpg" http://localhost:5001/translate
```

## ğŸ¯ ì˜ˆìƒ ê²°ê³¼

### í•™ìŠµ ì„±ëŠ¥
- **Baseline (CNN-LSTM)**: 70-80% ì •í™•ë„
- **Transformer**: 75-85% ì •í™•ë„  
- **Multi-modal**: 80-90% ì •í™•ë„

### ì‹¤ì‹œê°„ ì„±ëŠ¥
- **ì¶”ë¡  ì†ë„**: 10-50ms (GPU ê¸°ì¤€)
- **ì²˜ë¦¬ëŸ‰**: 20-100 FPS
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: 2-8GB (ëª¨ë¸ì— ë”°ë¼)

### ì‹œìŠ¤í…œ ì§€ì—°ì‹œê°„
- **ì „ì²´ íŒŒì´í”„ë¼ì¸**: 100-300ms
  - YOLO ê²€ì¶œ: 20-50ms
  - í¬ì¦ˆ ì¶”ì •: 30-80ms  
  - ìˆ˜í™” ì¸ì‹: 50-150ms

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```bash
   # ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
   --batch-size 2
   # ë˜ëŠ” CPU ì‚¬ìš©
   --device cpu
   ```

2. **ë°ì´í„° ë¡œë”© ì†ë„ ëŠë¦¼**
   ```bash
   # Worker ìˆ˜ ì¤„ì´ê¸°
   --num-workers 2
   ```

3. **h5py ì„¤ì¹˜ ì˜¤ë¥˜**
   ```bash
   pip install h5py==3.8.0
   ```

4. **í¬ì¦ˆ ì¶”ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**
   ```bash
   mkdir -p models
   wget https://download.openmmlab.com/mmpose/v1/whole_body_2d_keypoint/rtmpose/cocktail14/rtmw-dw-x-l_simcc-cocktail14_270e-384x288-f840f204_20231122.pth -P models/
   ```

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **ëª¨ë¸ ìµœì í™”**
   - Knowledge Distillationìœ¼ë¡œ ê²½ëŸ‰í™”
   - INT8 Quantization ì ìš©
   - ONNX/TensorRT ë³€í™˜

2. **ë°ì´í„° í™•ì¥**
   - ë” ë§ì€ ì°¸ì—¬ì ë°ì´í„° ì¶”ê°€
   - ë‹¤ì–‘í•œ ì‹œì  ë°ì´í„° í™œìš©
   - Data Augmentation ê°•í™”

3. **ì‹¤ì„œë¹„ìŠ¤ ë°°í¬**
   - Docker ì»¨í…Œì´ë„ˆí™”
   - Kubernetes ë°°í¬
   - Load Balancer êµ¬ì„±

4. **ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤**
   - ì›¹ ì¸í„°í˜ì´ìŠ¤ ê°œë°œ
   - ëª¨ë°”ì¼ ì•± ì—°ë™
   - ì‹¤ì‹œê°„ í”¼ë“œë°± ì‹œìŠ¤í…œ

---

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ë©´ ì™„ì „í•œ ìˆ˜í™” ì¸ì‹ AI ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰
