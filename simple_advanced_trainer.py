#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ë‹¤ë‹¨ê³„ í•™ìŠµ íŠ¸ë ˆì´ë„ˆ (í…ŒìŠ¤íŠ¸ìš©)
"""
import os
import time
import json
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
from tqdm import tqdm
import numpy as np

from sign_language_model import SequenceToSequenceSignModel
from sign_language_trainer import SignLanguageTrainer
from advanced_config import AdvancedTrainingConfig, TrainingStageConfig
from advanced_data_utils import StratifiedDataSplitter
from unified_pose_dataloader import UnifiedSignLanguageDataset

logger = logging.getLogger(__name__)

class SimpleEarlyStopping:
    """ê°„ë‹¨í•œ ì–¼ë¦¬ìŠ¤íƒ‘ í´ë˜ìŠ¤"""
    
    def __init__(self, patience=10, min_delta=1e-4):
        self.patience = patience
        self.min_delta = min_delta
        self.best_score = float('inf')
        self.wait = 0
        self.stopped_epoch = 0
        self.best_weights = None
        
    def __call__(self, current_score: float, epoch: int, model_state_dict: Dict) -> bool:
        """ì–¼ë¦¬ìŠ¤íƒ‘ ì²´í¬"""
        
        if current_score < (self.best_score - self.min_delta):
            self.best_score = current_score
            self.wait = 0
            self.best_weights = {k: v.clone() for k, v in model_state_dict.items()}
            logger.info(f"ğŸ‰ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! Val Loss: {current_score:.6f}")
        else:
            self.wait += 1
            logger.info(f"â³ ê°œì„  ì—†ìŒ ({self.wait}/{self.patience}) - í˜„ì¬: {current_score:.6f}, ìµœê³ : {self.best_score:.6f}")
        
        if self.wait >= self.patience:
            self.stopped_epoch = epoch
            logger.info(f"â¹ï¸ ì–¼ë¦¬ìŠ¤íƒ‘ ë°œë™! (ì—í¬í¬ {epoch})")
            return True
        
        return False
    
    def get_best_weights(self):
        """ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        return self.best_weights

class SimpleAdvancedTrainer:
    """ê°„ë‹¨í•œ ë‹¤ë‹¨ê³„ í•™ìŠµ íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, config: AdvancedTrainingConfig):
        self.config = config
        
        # ëœë¤ì‹œë“œ ê³ ì •
        self.config.random_seed.fix_all_seeds()
        logger.info(f"ğŸ² ëœë¤ì‹œë“œ ê³ ì •: {self.config.random_seed.seed}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.checkpoint_dir = Path(self.config.checkpoint_dir)
        self.log_dir = Path(self.config.log_dir)
        self.checkpoint_dir.mkdir(exist_ok=True)
        self.log_dir.mkdir(exist_ok=True)
        
        # í˜„ì¬ ìµœê³  ì„±ëŠ¥
        self.best_overall_performance = {
            'stage': None,
            'epoch': None,
            'val_loss': float('inf'),
            'val_accuracy': 0.0
        }
        
    def setup_device(self):
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        if self.config.device == "auto":
            if torch.cuda.is_available():
                device = torch.device("cuda")
                logger.info(f"ğŸ”¥ CUDA ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {torch.cuda.get_device_name()}")
            else:
                try:
                    import intel_extension_for_pytorch as ipex
                    device = torch.device("xpu")
                    logger.info("âš¡ XPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
                except:
                    device = torch.device("cpu")
                    logger.info("ğŸ’» CPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
        else:
            device = torch.device(self.config.device)
            logger.info(f"ğŸ¯ ì§€ì •ëœ ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {device}")
        
        return device
    
    def load_and_prepare_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ì¤€ë¹„"""
        logger.info("ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ì¤€ë¹„...")
        
        dataset = UnifiedSignLanguageDataset(
            annotation_path=self.config.annotation_path,
            pose_data_dir=self.config.pose_data_dir,
            sequence_length=200,
            min_segment_length=20,
            max_segment_length=300,
            enable_augmentation=False
        )
        
        logger.info(f"âœ… ê¸°ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(dataset)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
        
        # ë°ì´í„° ë¶„í• ê¸° ìƒì„±
        splitter = StratifiedDataSplitter(
            config=self.config.data_split,
            random_seed=self.config.random_seed.seed
        )
        
        return dataset, splitter
    
    def create_model(self, vocab_size: int) -> SequenceToSequenceSignModel:
        """ëª¨ë¸ ìƒì„±"""
        model = SequenceToSequenceSignModel(
            vocab_size=vocab_size,
            embed_dim=256,  # ì‘ê²Œ ì‹œì‘
            num_encoder_layers=4,  # ì‘ê²Œ ì‹œì‘
            num_decoder_layers=2,  # ì‘ê²Œ ì‹œì‘
            num_heads=8,
            dim_feedforward=512,  # ì‘ê²Œ ì‹œì‘
            max_seq_len=200,
            dropout=0.1
        )
        
        total_params = sum(p.numel() for p in model.parameters())
        logger.info(f"ğŸ“Š ëª¨ë¸ ìƒì„±: {total_params:,} íŒŒë¼ë¯¸í„°")
        
        return model
    
    def train_single_stage(self, 
                          stage_idx: int, 
                          stage_config: TrainingStageConfig, 
                          model: SequenceToSequenceSignModel,
                          base_dataset: UnifiedSignLanguageDataset,
                          splitter: StratifiedDataSplitter,
                          device: torch.device) -> Dict:
        """ë‹¨ì¼ ë‹¨ê³„ í•™ìŠµ"""
        
        logger.info("="*60)
        logger.info(f"ğŸš€ Stage {stage_idx+1}: {stage_config.name}")
        logger.info(f"ğŸ“ {stage_config.description}")
        logger.info(f"âš™ï¸ ì—í¬í¬: {stage_config.num_epochs}, ë°°ì¹˜: {stage_config.batch_size}")
        logger.info(f"âš™ï¸ í•™ìŠµë¥ : {stage_config.learning_rate}, ë“œë¡­ì•„ì›ƒ: {stage_config.dropout_rate}")
        logger.info("="*60)
        
        # ì¦ê°• ì„¤ì •
        augmentation_config = None
        if stage_config.enable_augmentation:
            augmentation_config = {
                'enable_horizontal_flip': True,
                'enable_rotation': True,
                'enable_scaling': True,
                'enable_noise': True,
                'horizontal_flip_prob': 0.5 * stage_config.augmentation_strength,
                'rotation_range': 10.0 * stage_config.augmentation_strength,
                'scaling_range': (1.0 - 0.05 * stage_config.augmentation_strength, 
                                 1.0 + 0.05 * stage_config.augmentation_strength),
                'noise_std': 0.005 * stage_config.augmentation_strength
            }
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_dataloader, val_dataloader, test_dataloader = splitter.create_dataloaders(
            dataset=base_dataset,
            batch_size=stage_config.batch_size,
            enable_train_augmentation=stage_config.enable_augmentation,
            augmentation_config=augmentation_config
        )
        
        # ì˜µí‹°ë§ˆì´ì € ìƒì„±
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=stage_config.learning_rate,
            weight_decay=stage_config.weight_decay
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', patience=3, factor=0.7
        )
        
        # ì–¼ë¦¬ìŠ¤íƒ‘ ì„¤ì •
        early_stopping = SimpleEarlyStopping(patience=8, min_delta=1e-4)
        
        # í•™ìŠµ ë£¨í”„
        stage_start_time = time.time()
        best_val_loss = float('inf')
        best_val_accuracy = 0.0
        best_epoch = -1
        
        for epoch in range(stage_config.num_epochs):
            epoch_start_time = time.time()
            
            # í›ˆë ¨
            model.train()
            total_train_loss = 0
            train_batches = 0
            
            train_pbar = tqdm(train_dataloader, desc=f"Epoch {epoch:2d} í›ˆë ¨")
            for batch in train_pbar:
                optimizer.zero_grad()
                
                # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
                pose_features = batch['pose_features'].to(device)
                vocab_ids = batch['vocab_ids'].to(device)
                frame_masks = batch['frame_masks'].to(device)
                vocab_masks = batch['vocab_masks'].to(device)
                
                # ìˆœì „íŒŒ
                outputs = model(
                    pose_features=pose_features,
                    vocab_ids=vocab_ids,
                    frame_masks=frame_masks,
                    vocab_masks=vocab_masks
                )
                
                # ì†ì‹¤ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
                if isinstance(outputs, dict) and 'vocab_logits' in outputs:
                    vocab_logits = outputs['vocab_logits']  # [batch, vocab_len, vocab_size]
                    
                    # íƒ€ê²Ÿ ì¤€ë¹„ (ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡)
                    targets = vocab_ids[:, 1:].contiguous()  # ë‹¤ìŒ ë‹¨ì–´ë“¤
                    logits = vocab_logits[:, :-1].contiguous()  # ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì œì™¸
                    
                    # ë§ˆìŠ¤í¬ ì¤€ë¹„
                    target_mask = vocab_masks[:, 1:].contiguous()
                    
                    # ì†ì‹¤ ê³„ì‚°
                    vocab_loss = nn.CrossEntropyLoss(ignore_index=0)(
                        logits.view(-1, logits.size(-1)),
                        targets.view(-1)
                    )
                    
                    loss = vocab_loss
                else:
                    # ë°±ì—…: ë”ë¯¸ ì†ì‹¤
                    loss = torch.tensor(0.0, requires_grad=True, device=device)
                
                # ì—­ì „íŒŒ
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                
                total_train_loss += loss.item()
                train_batches += 1
                
                train_pbar.set_postfix({
                    'loss': f'{loss.item():.4f}',
                    'avg_loss': f'{total_train_loss/train_batches:.4f}'
                })
            
            avg_train_loss = total_train_loss / max(train_batches, 1)
            
            # ê²€ì¦
            model.eval()
            total_val_loss = 0
            val_batches = 0
            correct_predictions = 0
            total_predictions = 0
            
            with torch.no_grad():
                val_pbar = tqdm(val_dataloader, desc=f"Epoch {epoch:2d} ê²€ì¦")
                for batch in val_pbar:
                    pose_features = batch['pose_features'].to(device)
                    vocab_ids = batch['vocab_ids'].to(device)
                    frame_masks = batch['frame_masks'].to(device)
                    vocab_masks = batch['vocab_masks'].to(device)
                    
                    outputs = model(
                        pose_features=pose_features,
                        vocab_ids=vocab_ids,
                        frame_masks=frame_masks,
                        vocab_masks=vocab_masks
                    )
                    
                    # ê²€ì¦ ì†ì‹¤ ê³„ì‚° (í›ˆë ¨ê³¼ ë™ì¼)
                    if isinstance(outputs, dict) and 'vocab_logits' in outputs:
                        vocab_logits = outputs['vocab_logits']
                        targets = vocab_ids[:, 1:].contiguous()
                        logits = vocab_logits[:, :-1].contiguous()
                        
                        vocab_loss = nn.CrossEntropyLoss(ignore_index=0)(
                            logits.view(-1, logits.size(-1)),
                            targets.view(-1)
                        )
                        
                        loss = vocab_loss
                        
                        # ì •í™•ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
                        predictions = torch.argmax(logits, dim=-1)
                        mask = targets != 0
                        correct_predictions += (predictions == targets)[mask].sum().item()
                        total_predictions += mask.sum().item()
                    else:
                        loss = torch.tensor(0.0, device=device)
                    
                    total_val_loss += loss.item()
                    val_batches += 1
                    
                    val_pbar.set_postfix({
                        'loss': f'{loss.item():.4f}',
                        'avg_loss': f'{total_val_loss/val_batches:.4f}'
                    })
            
            avg_val_loss = total_val_loss / max(val_batches, 1)
            val_accuracy = correct_predictions / max(total_predictions, 1)
            
            # ì„±ëŠ¥ ê¸°ë¡
            if avg_val_loss < best_val_loss:
                best_val_loss = avg_val_loss
                best_val_accuracy = val_accuracy
                best_epoch = epoch
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            scheduler.step(avg_val_loss)
            
            # ë¡œê¹…
            epoch_time = time.time() - epoch_start_time
            logger.info(f"Epoch {epoch:3d}/{stage_config.num_epochs-1} ({epoch_time:.1f}s)")
            logger.info(f"  Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}")
            logger.info(f"  Val Acc: {val_accuracy:.3f} | Best Val Loss: {best_val_loss:.4f}")
            
            # ì–¼ë¦¬ìŠ¤íƒ‘ ì²´í¬
            if early_stopping(avg_val_loss, epoch, model.state_dict()):
                logger.info(f"â¹ï¸ ì–¼ë¦¬ìŠ¤íƒ‘ ë°œë™ - Stage {stage_idx+1} ì¢…ë£Œ")
                
                # ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë³µì›
                if early_stopping.best_weights:
                    model.load_state_dict(early_stopping.best_weights)
                    logger.info("âœ… ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ ë³µì› ì™„ë£Œ")
                break
        
        # ë‹¨ê³„ ê²°ê³¼
        stage_results = {
            'stage_name': stage_config.name,
            'description': stage_config.description,
            'epochs_trained': epoch + 1,
            'best_epoch': best_epoch,
            'best_val_loss': best_val_loss,
            'best_val_accuracy': best_val_accuracy,
            'training_time': time.time() - stage_start_time
        }
        
        # ì „ì²´ ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
        if best_val_loss < self.best_overall_performance['val_loss']:
            self.best_overall_performance.update({
                'stage': stage_config.name,
                'epoch': best_epoch,
                'val_loss': best_val_loss,
                'val_accuracy': best_val_accuracy
            })
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            best_model_path = self.checkpoint_dir / f"best_model_stage_{stage_idx+1}.pt"
            torch.save({
                'stage': stage_config.name,
                'epoch': best_epoch,
                'model_state_dict': model.state_dict(),
                'val_loss': best_val_loss,
                'val_accuracy': best_val_accuracy
            }, best_model_path)
            logger.info(f"ğŸ’¾ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {best_model_path}")
        
        logger.info(f"âœ… Stage {stage_idx+1} ì™„ë£Œ!")
        logger.info(f"  ìµœê³  ì„±ëŠ¥: Val Loss {best_val_loss:.4f}, Val Acc {best_val_accuracy:.3f}")
        logger.info(f"  í•™ìŠµ ì‹œê°„: {stage_results['training_time']:.1f}ì´ˆ")
        
        return stage_results
    
    def train_multi_stage(self) -> Dict:
        """ë‹¤ë‹¨ê³„ í•™ìŠµ ì‹¤í–‰"""
        logger.info("ğŸš€ ê°„ë‹¨í•œ ë‹¤ë‹¨ê³„ í•™ìŠµ ì‹œì‘!")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = self.setup_device()
        
        # ë°ì´í„° ì¤€ë¹„
        base_dataset, splitter = self.load_and_prepare_data()
        
        # ëª¨ë¸ ìƒì„±
        model = self.create_model(base_dataset.vocab_size)
        model.to(device)
        
        # ê° ë‹¨ê³„ë³„ í•™ìŠµ
        all_stage_results = []
        
        for stage_idx, stage_config in enumerate(self.config.multi_stage.stages[:2]):  # ì²˜ìŒ 2ë‹¨ê³„ë§Œ
            stage_results = self.train_single_stage(
                stage_idx, stage_config, model, base_dataset, splitter, device
            )
            all_stage_results.append(stage_results)
            
            # ë„ˆë¬´ ì„±ëŠ¥ì´ ì•ˆ ì¢‹ìœ¼ë©´ ì¤‘ë‹¨
            if stage_results['best_val_loss'] > 10.0:
                logger.warning("âš ï¸ í•™ìŠµ ì„±ëŠ¥ì´ ë„ˆë¬´ ë‚˜ì¨. ì¡°ê¸° ì¢…ë£Œ")
                break
        
        # ê²°ê³¼ ìš”ì•½
        logger.info("\n" + "="*60)
        logger.info("ğŸ‰ ë‹¤ë‹¨ê³„ í•™ìŠµ ì™„ë£Œ!")
        logger.info("="*60)
        
        for i, stage in enumerate(all_stage_results):
            logger.info(f"Stage {i+1} ({stage['stage_name']}):")
            logger.info(f"  Val Loss: {stage['best_val_loss']:.4f}")
            logger.info(f"  Val Acc: {stage['best_val_accuracy']:.3f}")
            logger.info(f"  ì‹œê°„: {stage['training_time']:.1f}ì´ˆ")
        
        logger.info(f"\nğŸ† ìµœê³  ì„±ëŠ¥: {self.best_overall_performance['stage']}")
        logger.info(f"  Val Loss: {self.best_overall_performance['val_loss']:.4f}")
        logger.info(f"  Val Acc: {self.best_overall_performance['val_accuracy']:.3f}")
        
        return {
            'stages': all_stage_results,
            'best_performance': self.best_overall_performance
        }

if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    logging.basicConfig(level=logging.INFO)
    
    config = AdvancedTrainingConfig()
    # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„¤ì • ì¡°ì •
    for stage in config.multi_stage.stages:
        stage.num_epochs = 3
        stage.batch_size = 8
    
    trainer = SimpleAdvancedTrainer(config)
    results = trainer.train_multi_stage()
    
    print("âœ… ê°„ë‹¨í•œ ë‹¤ë‹¨ê³„ í•™ìŠµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
